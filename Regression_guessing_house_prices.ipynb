{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_guessing_house_prices.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPf7DyiZqZLF6SGRbXn7mAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spacemaninSeoul/justpractice/blob/main/Regression_guessing_house_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "보스턴 주택 가격 데이터셋은 연속적인 값을 예측하는 회귀(regression) 문제이다."
      ],
      "metadata": {
        "id": "8DGXl7UPYCO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 살펴보기"
      ],
      "metadata": {
        "id": "mMyBmfxqY49N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evJLlzwNX0az",
        "outputId": "7b2b0aa9-8a00-4574-f2ae-67565c90b49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 보스턴 주택 가격 데이터셋 다운받기\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터를 다운한다.\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz', test_split=0.2, seed=777)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 형태 확인\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wac5Le_pZOGR",
        "outputId": "d68a4c8e-79ec-4212-beea-cdd2e56f3a59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13) (404,)\n",
            "(102, 13) (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN-VedYrZncI",
        "outputId": "abe5b048-57b5-4e8b-f325-d0c1d9cc3bc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.5,  8.3, 17.2, 25. , 28.5, 23. , 18.9, 50. , 15.6, 38.7])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터는 13개의 특성이 있고, 레이블은 주택 가격의 중간 가격($1000 단위)을 나타낸다. 이 전에 다루었던 데이터셋처럼 특성의 스케일이 모두 동일하면 좋겠지만, 이번 데이터셋은 그렇지 않다. 예를 들어, 범죄율 같은 특성은 비율을 나타내기에 0~1의 값을 가지지만, 방의 개수 같은 경우는 3~9의 범위를 갖는다. 이러한 스케일의 문제는 신경망의 성능에 큰 영향을 미친다. 따라서 각 데이터 특성이 갖는 범위가 다를 때에는 범위가 동일하도록 조정해야만 한다. 이러한 문제를 해결할 때 대표적으로 사용하는 방법은 표준화(Standardization)를 수행하는 것이다."
      ],
      "metadata": {
        "id": "lXYkWjUFaM1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "표준화는 각 데이터의 특성에 대해서 평균을 빼고, 표준펹차로 나누어 준다. 이는 특성의 평균을 0으로, 표준편차를 1로 만들어준다."
      ],
      "metadata": {
        "id": "ESZK2eEYa4-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "NTZc1ci_bGmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 및 검증 데이터셋 만들기\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(x_train, axis=0)\n",
        "std = np.std(x_train, axis=0)\n",
        "\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# 검증 데이터셋을 만든다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.33, random_state = 777)"
      ],
      "metadata": {
        "id": "3nEp319AZu7i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드에서 주의해야 할 부분은 테스트셋의 전처리 과정에서 별도의 평균과 표준편차를 구하지 않고, 학습 데이터셋에서 얻은 평균과 표준편차를 사용하여 전처리를 진행했다는 점이다."
      ],
      "metadata": {
        "id": "6rr021CjdEsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모델 구성하기\n",
        "\n",
        "만약 데이터가 복잡하지 않고 개수가 매우 적다면, 모델을 깊게 쌓을수록 과대적합이 일어날 확률이 높으므로 주의해야 한다. 이를 생각하며 적절한 크기의 모델을 구성하도록 한다."
      ],
      "metadata": {
        "id": "xoAj_65RdMXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# 입력 데이터의 형태를 꼭 명시해야 한다.\n",
        "# 13차원의 데이터를 입력으로 받고, 64개의 출력을 가지는 첫 번쨰 Dense층\n",
        "model.add(Dense(64, activation='relu', input_shape = (13, )))\n",
        "model.add(Dense(32, activation='relu')) # 32개의 출력을 갖는 Dense층\n",
        "model.add(Dense(1)) # 하나의 값을 출력한다.\n",
        "\n",
        "model.compile(optimizer = 'adam', loss= 'mse', metrics= ['mae'])"
      ],
      "metadata": {
        "id": "nDAV7oG4ojJG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 마지막 Dense층에서 시그모이드 함수 또는 소프트맥스 함수를 사용하지 않았다. 왜냐하면 보스턴 주택 가격은 정답의 범위가 제한되지 않기 때문에 별도의 함수를 사용하지 않아야 하기 때문이다. activaiton 인자를 설정하지 않을 경우, Dense층의 활성화 함수는 자동으로 linear로 설정된다.\n",
        "\n",
        "손실 함수는 회귀 문제에서 주로 사용되는 평균 제곱 오차(MSE: Mean Squared Error)를 사용한다. 이 함수는 정답과 예측값 사이 거리의 제곱이다.\n",
        "\n",
        "평가지표로는 평균 절대 오차(MAE: Mean Absolute Error)를 사용했다. 회귀 문제는 분류 문제와 다른 손실 함수와 평가 지료를 사용한다."
      ],
      "metadata": {
        "id": "6H7oHYi6pUZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "KD6u6W48qWva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델 학습과 평가\n"
      ],
      "metadata": {
        "id": "5_HKW9deqTJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "history = model.fit(x_train, y_train, epochs = 300, validation_data = (x_val, y_val))\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuZY1ZxJqna6",
        "outputId": "696e2ee7-cd0a-4425-dd45-d7031c392bbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 27ms/step - loss: 527.3445 - mae: 21.2845 - val_loss: 574.0509 - val_mae: 21.7243\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 498.0210 - mae: 20.5904 - val_loss: 541.3154 - val_mae: 20.9770\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 466.2508 - mae: 19.8202 - val_loss: 504.8604 - val_mae: 20.1102\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 429.9260 - mae: 18.9131 - val_loss: 461.8567 - val_mae: 19.0526\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 388.2457 - mae: 17.8238 - val_loss: 412.4136 - val_mae: 17.7627\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 340.3808 - mae: 16.5294 - val_loss: 357.5819 - val_mae: 16.2894\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 287.0175 - mae: 15.0166 - val_loss: 298.7782 - val_mae: 14.6032\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 230.9376 - mae: 13.2658 - val_loss: 238.7229 - val_mae: 12.7311\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 176.8852 - mae: 11.3404 - val_loss: 182.7192 - val_mae: 10.8389\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 129.3352 - mae: 9.4793 - val_loss: 137.1874 - val_mae: 9.1547\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 92.1706 - mae: 7.8472 - val_loss: 106.1158 - val_mae: 8.0076\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 69.0631 - mae: 6.7193 - val_loss: 86.0051 - val_mae: 7.1328\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 55.2601 - mae: 5.9327 - val_loss: 72.6942 - val_mae: 6.4644\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 45.9783 - mae: 5.2866 - val_loss: 61.5184 - val_mae: 5.8599\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 38.7727 - mae: 4.7278 - val_loss: 52.8971 - val_mae: 5.3644\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 33.3900 - mae: 4.3003 - val_loss: 46.6087 - val_mae: 4.9966\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 29.5352 - mae: 3.9823 - val_loss: 42.0580 - val_mae: 4.7051\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.9643 - mae: 3.7906 - val_loss: 38.7159 - val_mae: 4.5002\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.9213 - mae: 3.5990 - val_loss: 36.0259 - val_mae: 4.2962\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.5971 - mae: 3.4680 - val_loss: 34.0629 - val_mae: 4.1665\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.4460 - mae: 3.3578 - val_loss: 32.5609 - val_mae: 4.0427\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.7258 - mae: 3.2776 - val_loss: 31.3099 - val_mae: 3.9537\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.0183 - mae: 3.2202 - val_loss: 30.3555 - val_mae: 3.8875\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.4841 - mae: 3.1557 - val_loss: 29.7034 - val_mae: 3.7960\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.9934 - mae: 3.1038 - val_loss: 28.8891 - val_mae: 3.7461\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.4967 - mae: 3.0614 - val_loss: 28.2036 - val_mae: 3.6972\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.0702 - mae: 3.0239 - val_loss: 27.2975 - val_mae: 3.6155\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.6596 - mae: 2.9962 - val_loss: 26.7416 - val_mae: 3.5823\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.2826 - mae: 2.9645 - val_loss: 26.0146 - val_mae: 3.5314\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.8830 - mae: 2.9313 - val_loss: 25.5798 - val_mae: 3.4978\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.5633 - mae: 2.9075 - val_loss: 25.1749 - val_mae: 3.4788\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.2112 - mae: 2.8707 - val_loss: 24.7071 - val_mae: 3.4363\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.8920 - mae: 2.8354 - val_loss: 24.3340 - val_mae: 3.4114\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.6510 - mae: 2.8042 - val_loss: 23.9945 - val_mae: 3.3744\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.2952 - mae: 2.7790 - val_loss: 23.3565 - val_mae: 3.3812\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.1042 - mae: 2.7819 - val_loss: 22.8238 - val_mae: 3.3562\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.8228 - mae: 2.7503 - val_loss: 22.5361 - val_mae: 3.3091\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.5163 - mae: 2.7116 - val_loss: 22.5161 - val_mae: 3.2810\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.2824 - mae: 2.6722 - val_loss: 22.2689 - val_mae: 3.2409\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.0671 - mae: 2.6451 - val_loss: 22.0588 - val_mae: 3.2250\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.9177 - mae: 2.6252 - val_loss: 21.8332 - val_mae: 3.1972\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.7132 - mae: 2.6037 - val_loss: 21.5830 - val_mae: 3.1879\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.5126 - mae: 2.5865 - val_loss: 21.2173 - val_mae: 3.1364\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.2857 - mae: 2.5695 - val_loss: 20.9003 - val_mae: 3.1457\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.0923 - mae: 2.5596 - val_loss: 20.6657 - val_mae: 3.1471\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.9275 - mae: 2.5384 - val_loss: 20.5000 - val_mae: 3.1181\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7623 - mae: 2.5253 - val_loss: 20.2969 - val_mae: 3.0926\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.5724 - mae: 2.5067 - val_loss: 20.0665 - val_mae: 3.0954\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4337 - mae: 2.4956 - val_loss: 19.8263 - val_mae: 3.0874\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3001 - mae: 2.4872 - val_loss: 19.5033 - val_mae: 3.0745\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1880 - mae: 2.4771 - val_loss: 19.4079 - val_mae: 3.0583\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.9797 - mae: 2.4578 - val_loss: 19.2112 - val_mae: 3.0418\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.8643 - mae: 2.4448 - val_loss: 19.1084 - val_mae: 3.0177\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.7801 - mae: 2.4358 - val_loss: 18.7385 - val_mae: 2.9823\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.6251 - mae: 2.4220 - val_loss: 18.7250 - val_mae: 2.9807\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5034 - mae: 2.4104 - val_loss: 18.6899 - val_mae: 2.9786\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5070 - mae: 2.4238 - val_loss: 18.1079 - val_mae: 2.9917\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3088 - mae: 2.4129 - val_loss: 18.0908 - val_mae: 2.9690\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1787 - mae: 2.3920 - val_loss: 18.1739 - val_mae: 2.9519\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0707 - mae: 2.3704 - val_loss: 17.8731 - val_mae: 2.9161\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.9297 - mae: 2.3725 - val_loss: 17.7083 - val_mae: 2.9131\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.8738 - mae: 2.3674 - val_loss: 17.7283 - val_mae: 2.9163\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.7540 - mae: 2.3552 - val_loss: 17.4703 - val_mae: 2.8990\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.6150 - mae: 2.3432 - val_loss: 17.3934 - val_mae: 2.8794\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5480 - mae: 2.3371 - val_loss: 17.1796 - val_mae: 2.8778\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4339 - mae: 2.3328 - val_loss: 17.0129 - val_mae: 2.8698\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3651 - mae: 2.3272 - val_loss: 17.0039 - val_mae: 2.8601\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3246 - mae: 2.3216 - val_loss: 17.1803 - val_mae: 2.8738\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1902 - mae: 2.2999 - val_loss: 17.0524 - val_mae: 2.8519\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1222 - mae: 2.2964 - val_loss: 16.8047 - val_mae: 2.8275\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.0560 - mae: 2.2935 - val_loss: 16.6516 - val_mae: 2.8164\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.9842 - mae: 2.2895 - val_loss: 16.6191 - val_mae: 2.8140\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9192 - mae: 2.2848 - val_loss: 16.5598 - val_mae: 2.8337\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8273 - mae: 2.2759 - val_loss: 16.6539 - val_mae: 2.8262\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.7749 - mae: 2.2536 - val_loss: 16.5599 - val_mae: 2.7974\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7130 - mae: 2.2486 - val_loss: 16.2773 - val_mae: 2.7953\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6641 - mae: 2.2464 - val_loss: 16.5269 - val_mae: 2.8014\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.6138 - mae: 2.2320 - val_loss: 16.4978 - val_mae: 2.7899\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4930 - mae: 2.2258 - val_loss: 16.1819 - val_mae: 2.7932\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4237 - mae: 2.2284 - val_loss: 16.0670 - val_mae: 2.7918\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4324 - mae: 2.2401 - val_loss: 15.7838 - val_mae: 2.7668\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3365 - mae: 2.2237 - val_loss: 16.0691 - val_mae: 2.7878\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2992 - mae: 2.2108 - val_loss: 16.1207 - val_mae: 2.7834\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1998 - mae: 2.1980 - val_loss: 15.8486 - val_mae: 2.7647\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1379 - mae: 2.1973 - val_loss: 15.5812 - val_mae: 2.7486\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1042 - mae: 2.2003 - val_loss: 15.3510 - val_mae: 2.7332\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0492 - mae: 2.1934 - val_loss: 15.6422 - val_mae: 2.7304\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0122 - mae: 2.1800 - val_loss: 15.5708 - val_mae: 2.7226\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9174 - mae: 2.1774 - val_loss: 15.3751 - val_mae: 2.7398\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8778 - mae: 2.1863 - val_loss: 15.0132 - val_mae: 2.7059\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8280 - mae: 2.1765 - val_loss: 15.0370 - val_mae: 2.7006\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7801 - mae: 2.1606 - val_loss: 15.1963 - val_mae: 2.7018\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7455 - mae: 2.1569 - val_loss: 15.3289 - val_mae: 2.7146\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6501 - mae: 2.1471 - val_loss: 15.1753 - val_mae: 2.7039\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6072 - mae: 2.1476 - val_loss: 15.0495 - val_mae: 2.6928\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5961 - mae: 2.1452 - val_loss: 14.9968 - val_mae: 2.6719\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5509 - mae: 2.1334 - val_loss: 15.1829 - val_mae: 2.7005\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4768 - mae: 2.1286 - val_loss: 14.8463 - val_mae: 2.6800\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4092 - mae: 2.1143 - val_loss: 14.6924 - val_mae: 2.6421\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3986 - mae: 2.1171 - val_loss: 14.6569 - val_mae: 2.6440\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3556 - mae: 2.1211 - val_loss: 14.7545 - val_mae: 2.6679\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2801 - mae: 2.1129 - val_loss: 14.6552 - val_mae: 2.6636\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2678 - mae: 2.1107 - val_loss: 14.5382 - val_mae: 2.6508\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2617 - mae: 2.1005 - val_loss: 14.7633 - val_mae: 2.6462\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1290 - mae: 2.0873 - val_loss: 14.4311 - val_mae: 2.6398\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0930 - mae: 2.0966 - val_loss: 14.2288 - val_mae: 2.6374\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0707 - mae: 2.0913 - val_loss: 14.4964 - val_mae: 2.6404\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.9976 - mae: 2.0752 - val_loss: 14.3421 - val_mae: 2.6346\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9905 - mae: 2.0891 - val_loss: 14.3893 - val_mae: 2.6457\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9560 - mae: 2.0725 - val_loss: 14.4359 - val_mae: 2.6308\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8881 - mae: 2.0612 - val_loss: 14.3106 - val_mae: 2.6311\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8412 - mae: 2.0563 - val_loss: 14.1726 - val_mae: 2.6095\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7837 - mae: 2.0474 - val_loss: 14.2706 - val_mae: 2.6144\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7700 - mae: 2.0510 - val_loss: 14.1772 - val_mae: 2.6204\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7291 - mae: 2.0548 - val_loss: 14.2601 - val_mae: 2.6355\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6666 - mae: 2.0526 - val_loss: 13.9345 - val_mae: 2.6057\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6274 - mae: 2.0474 - val_loss: 14.0335 - val_mae: 2.6099\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5925 - mae: 2.0418 - val_loss: 13.7971 - val_mae: 2.5807\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5726 - mae: 2.0378 - val_loss: 13.7486 - val_mae: 2.5711\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5016 - mae: 2.0240 - val_loss: 13.7760 - val_mae: 2.5854\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4635 - mae: 2.0325 - val_loss: 13.9336 - val_mae: 2.6086\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4419 - mae: 2.0266 - val_loss: 13.9099 - val_mae: 2.5982\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3716 - mae: 2.0123 - val_loss: 13.7955 - val_mae: 2.5809\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3866 - mae: 2.0111 - val_loss: 13.6584 - val_mae: 2.5589\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3164 - mae: 2.0138 - val_loss: 13.7064 - val_mae: 2.5860\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3379 - mae: 2.0109 - val_loss: 13.5644 - val_mae: 2.5600\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2858 - mae: 2.0019 - val_loss: 13.5155 - val_mae: 2.5660\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1661 - mae: 2.0008 - val_loss: 13.2538 - val_mae: 2.5411\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1599 - mae: 1.9997 - val_loss: 13.2926 - val_mae: 2.5417\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0880 - mae: 1.9814 - val_loss: 13.5323 - val_mae: 2.5510\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0930 - mae: 1.9744 - val_loss: 13.6950 - val_mae: 2.5663\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0520 - mae: 2.0017 - val_loss: 12.9582 - val_mae: 2.5163\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9719 - mae: 1.9946 - val_loss: 13.2123 - val_mae: 2.5511\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0099 - mae: 1.9833 - val_loss: 13.1852 - val_mae: 2.5296\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9615 - mae: 1.9849 - val_loss: 13.2309 - val_mae: 2.5505\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8297 - mae: 1.9683 - val_loss: 13.3274 - val_mae: 2.5399\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8237 - mae: 1.9522 - val_loss: 13.2861 - val_mae: 2.5327\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8070 - mae: 1.9535 - val_loss: 13.2164 - val_mae: 2.5420\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7483 - mae: 1.9421 - val_loss: 13.4263 - val_mae: 2.5497\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7190 - mae: 1.9433 - val_loss: 13.1035 - val_mae: 2.5234\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7046 - mae: 1.9536 - val_loss: 12.9506 - val_mae: 2.5181\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6023 - mae: 1.9444 - val_loss: 13.0907 - val_mae: 2.5245\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6266 - mae: 1.9439 - val_loss: 13.0381 - val_mae: 2.5209\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5241 - mae: 1.9280 - val_loss: 12.9405 - val_mae: 2.5065\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5000 - mae: 1.9255 - val_loss: 12.6437 - val_mae: 2.4832\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4699 - mae: 1.9350 - val_loss: 12.7474 - val_mae: 2.5149\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4830 - mae: 1.9316 - val_loss: 12.7160 - val_mae: 2.4926\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3936 - mae: 1.9203 - val_loss: 12.4759 - val_mae: 2.4873\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3874 - mae: 1.9183 - val_loss: 12.7937 - val_mae: 2.5114\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3144 - mae: 1.8994 - val_loss: 12.7589 - val_mae: 2.5023\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2833 - mae: 1.9093 - val_loss: 12.4974 - val_mae: 2.4839\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2433 - mae: 1.9110 - val_loss: 12.6523 - val_mae: 2.4786\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1698 - mae: 1.8819 - val_loss: 12.5832 - val_mae: 2.4782\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1471 - mae: 1.8840 - val_loss: 12.5066 - val_mae: 2.4777\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2288 - mae: 1.9191 - val_loss: 12.2357 - val_mae: 2.4784\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1145 - mae: 1.9196 - val_loss: 12.2841 - val_mae: 2.4636\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1339 - mae: 1.8851 - val_loss: 12.4583 - val_mae: 2.4877\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2058 - mae: 1.9154 - val_loss: 12.1377 - val_mae: 2.4953\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0435 - mae: 1.9092 - val_loss: 12.2149 - val_mae: 2.4707\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9288 - mae: 1.8606 - val_loss: 12.3051 - val_mae: 2.4670\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8980 - mae: 1.8515 - val_loss: 12.1660 - val_mae: 2.4452\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8588 - mae: 1.8465 - val_loss: 12.2598 - val_mae: 2.4645\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8375 - mae: 1.8424 - val_loss: 12.2474 - val_mae: 2.4539\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7814 - mae: 1.8607 - val_loss: 12.0132 - val_mae: 2.4663\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7687 - mae: 1.8834 - val_loss: 11.9608 - val_mae: 2.4411\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7393 - mae: 1.8489 - val_loss: 12.1407 - val_mae: 2.4539\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7229 - mae: 1.8529 - val_loss: 11.9113 - val_mae: 2.4400\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6106 - mae: 1.8422 - val_loss: 12.0765 - val_mae: 2.4499\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5569 - mae: 1.8109 - val_loss: 12.1326 - val_mae: 2.4453\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5409 - mae: 1.8150 - val_loss: 12.1694 - val_mae: 2.4590\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5133 - mae: 1.8249 - val_loss: 11.8084 - val_mae: 2.4235\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4647 - mae: 1.8099 - val_loss: 12.1180 - val_mae: 2.4391\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4352 - mae: 1.8015 - val_loss: 11.9591 - val_mae: 2.4403\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4304 - mae: 1.7992 - val_loss: 12.2842 - val_mae: 2.4655\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4014 - mae: 1.8081 - val_loss: 11.9673 - val_mae: 2.4524\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3598 - mae: 1.8014 - val_loss: 12.0109 - val_mae: 2.4422\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2893 - mae: 1.7802 - val_loss: 11.7492 - val_mae: 2.4254\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2717 - mae: 1.8061 - val_loss: 11.6921 - val_mae: 2.4217\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2635 - mae: 1.7788 - val_loss: 12.0351 - val_mae: 2.4361\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2164 - mae: 1.7703 - val_loss: 11.8318 - val_mae: 2.4286\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1638 - mae: 1.7874 - val_loss: 11.8619 - val_mae: 2.4467\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1304 - mae: 1.7697 - val_loss: 11.8415 - val_mae: 2.4334\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1345 - mae: 1.7603 - val_loss: 11.8886 - val_mae: 2.4213\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1192 - mae: 1.7612 - val_loss: 11.9116 - val_mae: 2.4451\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0622 - mae: 1.7493 - val_loss: 11.6068 - val_mae: 2.4058\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0212 - mae: 1.7501 - val_loss: 11.7488 - val_mae: 2.4340\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9833 - mae: 1.7583 - val_loss: 11.6837 - val_mae: 2.4340\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9629 - mae: 1.7539 - val_loss: 11.7843 - val_mae: 2.4446\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9218 - mae: 1.7496 - val_loss: 11.5905 - val_mae: 2.4301\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8564 - mae: 1.7255 - val_loss: 11.6360 - val_mae: 2.4082\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8576 - mae: 1.7150 - val_loss: 11.5616 - val_mae: 2.4063\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8346 - mae: 1.7336 - val_loss: 11.4881 - val_mae: 2.4300\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8291 - mae: 1.7408 - val_loss: 11.4639 - val_mae: 2.3987\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8155 - mae: 1.7143 - val_loss: 11.6823 - val_mae: 2.4135\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6698 - mae: 1.7089 - val_loss: 11.2258 - val_mae: 2.4091\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7463 - mae: 1.7408 - val_loss: 11.1765 - val_mae: 2.3959\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6531 - mae: 1.7231 - val_loss: 11.3587 - val_mae: 2.3874\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6707 - mae: 1.7070 - val_loss: 11.4144 - val_mae: 2.3987\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6073 - mae: 1.7052 - val_loss: 11.6175 - val_mae: 2.4442\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6074 - mae: 1.7201 - val_loss: 11.2248 - val_mae: 2.3885\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6467 - mae: 1.6994 - val_loss: 11.3527 - val_mae: 2.3802\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5119 - mae: 1.6823 - val_loss: 11.3533 - val_mae: 2.4142\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5664 - mae: 1.6919 - val_loss: 11.2581 - val_mae: 2.3892\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4572 - mae: 1.6812 - val_loss: 11.0769 - val_mae: 2.3720\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4393 - mae: 1.6805 - val_loss: 11.2766 - val_mae: 2.3916\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3991 - mae: 1.6640 - val_loss: 11.1020 - val_mae: 2.3801\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3670 - mae: 1.6722 - val_loss: 11.2272 - val_mae: 2.3954\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3985 - mae: 1.6535 - val_loss: 11.3162 - val_mae: 2.3846\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3135 - mae: 1.6436 - val_loss: 11.2949 - val_mae: 2.4075\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3098 - mae: 1.6592 - val_loss: 11.0909 - val_mae: 2.3776\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2925 - mae: 1.6387 - val_loss: 11.4009 - val_mae: 2.3907\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2164 - mae: 1.6239 - val_loss: 11.2980 - val_mae: 2.4143\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2488 - mae: 1.6591 - val_loss: 11.0875 - val_mae: 2.3767\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1971 - mae: 1.6304 - val_loss: 11.4028 - val_mae: 2.3873\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1662 - mae: 1.6127 - val_loss: 11.3595 - val_mae: 2.4165\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1615 - mae: 1.6372 - val_loss: 11.1622 - val_mae: 2.4007\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1195 - mae: 1.6343 - val_loss: 11.0514 - val_mae: 2.3545\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1832 - mae: 1.6082 - val_loss: 11.3743 - val_mae: 2.4053\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0584 - mae: 1.6145 - val_loss: 10.9019 - val_mae: 2.3559\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0582 - mae: 1.6209 - val_loss: 11.0492 - val_mae: 2.3697\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0261 - mae: 1.6053 - val_loss: 11.2259 - val_mae: 2.3900\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9932 - mae: 1.5940 - val_loss: 11.0709 - val_mae: 2.3602\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9548 - mae: 1.5979 - val_loss: 11.2358 - val_mae: 2.4023\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9515 - mae: 1.5832 - val_loss: 11.2991 - val_mae: 2.3988\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9106 - mae: 1.5861 - val_loss: 10.9952 - val_mae: 2.3675\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8509 - mae: 1.5876 - val_loss: 11.0849 - val_mae: 2.3841\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9178 - mae: 1.5762 - val_loss: 11.3198 - val_mae: 2.4000\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8111 - mae: 1.5768 - val_loss: 10.9609 - val_mae: 2.3811\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8138 - mae: 1.5871 - val_loss: 11.0069 - val_mae: 2.3765\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7758 - mae: 1.5648 - val_loss: 11.1472 - val_mae: 2.3639\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7450 - mae: 1.5682 - val_loss: 10.9688 - val_mae: 2.3704\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7426 - mae: 1.5621 - val_loss: 11.1186 - val_mae: 2.3644\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6889 - mae: 1.5417 - val_loss: 10.8314 - val_mae: 2.3500\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6603 - mae: 1.5586 - val_loss: 10.7522 - val_mae: 2.3431\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6202 - mae: 1.5409 - val_loss: 10.9749 - val_mae: 2.3534\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6005 - mae: 1.5329 - val_loss: 10.9045 - val_mae: 2.3565\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5662 - mae: 1.5370 - val_loss: 10.9580 - val_mae: 2.3635\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5823 - mae: 1.5363 - val_loss: 10.9638 - val_mae: 2.3719\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5397 - mae: 1.5125 - val_loss: 10.8938 - val_mae: 2.3359\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5287 - mae: 1.5260 - val_loss: 10.7586 - val_mae: 2.3341\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4980 - mae: 1.5211 - val_loss: 11.0740 - val_mae: 2.3751\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4622 - mae: 1.5042 - val_loss: 10.9833 - val_mae: 2.3672\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5341 - mae: 1.5524 - val_loss: 10.7212 - val_mae: 2.3435\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4864 - mae: 1.5165 - val_loss: 10.9876 - val_mae: 2.3443\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4236 - mae: 1.5108 - val_loss: 10.9657 - val_mae: 2.3647\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3677 - mae: 1.5033 - val_loss: 10.9663 - val_mae: 2.3552\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3261 - mae: 1.4930 - val_loss: 10.8497 - val_mae: 2.3403\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3317 - mae: 1.4781 - val_loss: 10.9224 - val_mae: 2.3593\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2949 - mae: 1.4768 - val_loss: 10.9127 - val_mae: 2.3503\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2746 - mae: 1.4846 - val_loss: 11.0153 - val_mae: 2.3646\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3090 - mae: 1.4740 - val_loss: 11.0833 - val_mae: 2.3615\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2035 - mae: 1.4589 - val_loss: 10.9478 - val_mae: 2.3753\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2201 - mae: 1.4705 - val_loss: 10.7359 - val_mae: 2.3345\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2215 - mae: 1.4614 - val_loss: 10.8670 - val_mae: 2.3535\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1875 - mae: 1.4674 - val_loss: 10.8815 - val_mae: 2.3560\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1559 - mae: 1.4476 - val_loss: 10.9910 - val_mae: 2.3586\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1540 - mae: 1.4582 - val_loss: 10.7162 - val_mae: 2.3271\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2260 - mae: 1.4604 - val_loss: 11.1251 - val_mae: 2.3581\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1044 - mae: 1.4442 - val_loss: 10.8344 - val_mae: 2.3687\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0527 - mae: 1.4393 - val_loss: 11.1550 - val_mae: 2.3781\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0472 - mae: 1.4144 - val_loss: 10.8761 - val_mae: 2.3491\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0447 - mae: 1.4587 - val_loss: 10.6832 - val_mae: 2.3379\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9634 - mae: 1.4279 - val_loss: 10.8432 - val_mae: 2.3087\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0236 - mae: 1.4134 - val_loss: 10.8519 - val_mae: 2.3519\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0630 - mae: 1.4359 - val_loss: 10.7174 - val_mae: 2.3179\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9684 - mae: 1.4398 - val_loss: 11.0022 - val_mae: 2.3688\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9513 - mae: 1.4065 - val_loss: 11.0371 - val_mae: 2.3487\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8584 - mae: 1.4038 - val_loss: 10.7220 - val_mae: 2.3432\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8768 - mae: 1.4238 - val_loss: 10.8953 - val_mae: 2.3566\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8492 - mae: 1.3945 - val_loss: 10.8524 - val_mae: 2.3233\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7913 - mae: 1.3804 - val_loss: 10.7611 - val_mae: 2.3401\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8181 - mae: 1.4095 - val_loss: 10.6450 - val_mae: 2.3207\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7642 - mae: 1.3806 - val_loss: 10.8924 - val_mae: 2.3270\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8249 - mae: 1.3625 - val_loss: 10.9203 - val_mae: 2.3217\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7307 - mae: 1.3784 - val_loss: 10.9028 - val_mae: 2.3632\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7494 - mae: 1.3929 - val_loss: 10.8837 - val_mae: 2.3317\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7362 - mae: 1.3706 - val_loss: 10.7633 - val_mae: 2.3163\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6806 - mae: 1.3827 - val_loss: 10.7716 - val_mae: 2.3476\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6855 - mae: 1.3665 - val_loss: 10.7711 - val_mae: 2.3040\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6497 - mae: 1.3781 - val_loss: 10.7946 - val_mae: 2.3365\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6040 - mae: 1.3538 - val_loss: 10.7959 - val_mae: 2.3205\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6040 - mae: 1.3412 - val_loss: 10.7794 - val_mae: 2.3105\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5520 - mae: 1.3286 - val_loss: 10.7052 - val_mae: 2.3219\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5876 - mae: 1.3559 - val_loss: 10.8179 - val_mae: 2.3286\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5568 - mae: 1.3524 - val_loss: 10.7205 - val_mae: 2.3252\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6449 - mae: 1.3458 - val_loss: 10.6854 - val_mae: 2.3012\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7591 - mae: 1.4060 - val_loss: 10.8485 - val_mae: 2.3865\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5521 - mae: 1.3660 - val_loss: 10.7271 - val_mae: 2.2860\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5154 - mae: 1.3381 - val_loss: 10.9368 - val_mae: 2.3642\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4945 - mae: 1.3569 - val_loss: 10.7691 - val_mae: 2.3073\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4180 - mae: 1.3036 - val_loss: 10.8596 - val_mae: 2.3097\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4469 - mae: 1.3082 - val_loss: 10.7903 - val_mae: 2.3223\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3933 - mae: 1.3301 - val_loss: 10.8546 - val_mae: 2.3409\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3368 - mae: 1.2970 - val_loss: 10.9237 - val_mae: 2.3140\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3427 - mae: 1.2964 - val_loss: 10.8321 - val_mae: 2.3171\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3491 - mae: 1.3054 - val_loss: 10.8782 - val_mae: 2.3265\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3055 - mae: 1.3083 - val_loss: 10.7721 - val_mae: 2.3125\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3567 - mae: 1.3066 - val_loss: 11.1433 - val_mae: 2.3563\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3124 - mae: 1.3085 - val_loss: 10.6821 - val_mae: 2.3371\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3176 - mae: 1.3289 - val_loss: 10.7209 - val_mae: 2.3078\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.9034 - mae: 2.0978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.90342903137207, 2.0977935791015625]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 점수로 2.1 정도를 얻었다. 이는 주택의 실제 가격과 예측 가격이 평균적으로 2,200 달러 정도 차이가 있다는 것을 말한다."
      ],
      "metadata": {
        "id": "KWM6eeKGrJX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 개수가 적은 경우 모델의 성능을 향상시킬 수 있는 좋은 방법으로 교차 검증이 있다. 여기에서는 K-폴드 교차 검증을 사용하도록 한다. 이번 예제에서는 결과보다 K-폴드를 사용하는 방법을 중점에 두고 진행한다. 표준화 과정까지는 동일하지만, 검증 데이터셋은 직접 만들어두지 않는다. sklearn.model_selection 모듈의 KFold 함수를 통해 자동으로 생성한다."
      ],
      "metadata": {
        "id": "QmO9kLSmrR-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-폴드 사용하기\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz', test_split=0.2, seed=777)\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(x_train, axis = 0)\n",
        "std = np.std(x_train, axis=0)\n",
        "# 여기까지는 동일\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# K-폴드를 진행한다\n",
        "k = 3\n",
        "\n",
        "# 주어진 데이터셋을 k만큼 등분한다.\n",
        "# 여기서는 3이므로 학습 데이터셋(404개)을 3등분하여 한 개는 검증셋으로, 나머지 두 개는 학습 데이터셋으로 사용한다.\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# k-폴드 과정에서 재사용을 위해 모델을 반환하는 함수를 정의\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "mae_list = [] # 테스트셋을 평가한 후 결과 mae를 담을 리스트를 선언한다.\n",
        "\n",
        "# k번 진행한다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "  # 해당 인덱스는 무작위로 생성된다.\n",
        "  # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법이다.\n",
        "  x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "  # 모델을 불러오기.\n",
        "  model = get_model()\n",
        "\n",
        "  model.fit(x_train_fold, y_train_fold, epochs = 300,\n",
        "            validation_data = (x_val_fold, y_val_fold))\n",
        "  \n",
        "  _, test_mae = model.evaluate(x_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3qCiodJriZv",
        "outputId": "a08960d2-a6d9-4708-c738-480234e7b4b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 23ms/step - loss: 543.4766 - mae: 21.3730 - val_loss: 515.6574 - val_mae: 20.7692\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 508.6595 - mae: 20.5668 - val_loss: 480.9406 - val_mae: 19.9202\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 468.7269 - mae: 19.6066 - val_loss: 440.3984 - val_mae: 18.9022\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 420.3224 - mae: 18.4517 - val_loss: 392.7912 - val_mae: 17.6686\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 364.7112 - mae: 17.0129 - val_loss: 335.1084 - val_mae: 16.0982\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 299.2847 - mae: 15.2110 - val_loss: 271.4678 - val_mae: 14.2147\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 232.5167 - mae: 13.1143 - val_loss: 207.4517 - val_mae: 12.0658\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 171.6139 - mae: 10.9106 - val_loss: 151.1097 - val_mae: 9.9956\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 122.1264 - mae: 8.9655 - val_loss: 108.7408 - val_mae: 8.2069\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 91.5556 - mae: 7.5753 - val_loss: 81.0289 - val_mae: 6.9739\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 73.3811 - mae: 6.7331 - val_loss: 64.6627 - val_mae: 6.2191\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.1431 - mae: 6.1976 - val_loss: 54.5278 - val_mae: 5.6586\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 55.0501 - mae: 5.7561 - val_loss: 47.1329 - val_mae: 5.1810\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 48.3001 - mae: 5.3358 - val_loss: 41.1034 - val_mae: 4.7253\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 42.0706 - mae: 4.9404 - val_loss: 37.1697 - val_mae: 4.4068\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 37.7571 - mae: 4.6239 - val_loss: 33.8251 - val_mae: 4.1191\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 34.1917 - mae: 4.3493 - val_loss: 30.9955 - val_mae: 3.9079\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31.3003 - mae: 4.1056 - val_loss: 28.7462 - val_mae: 3.7540\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 28.8652 - mae: 3.8760 - val_loss: 27.3865 - val_mae: 3.6668\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.9861 - mae: 3.7052 - val_loss: 25.8120 - val_mae: 3.5917\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25.2982 - mae: 3.5868 - val_loss: 24.7204 - val_mae: 3.5369\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.9519 - mae: 3.4805 - val_loss: 23.9523 - val_mae: 3.4939\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.8932 - mae: 3.3700 - val_loss: 23.4485 - val_mae: 3.4595\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.8499 - mae: 3.2628 - val_loss: 22.9694 - val_mae: 3.4307\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.1115 - mae: 3.1979 - val_loss: 22.4310 - val_mae: 3.4199\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.3329 - mae: 3.1328 - val_loss: 22.0741 - val_mae: 3.4045\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.7125 - mae: 3.0726 - val_loss: 21.8010 - val_mae: 3.3798\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 19.0377 - mae: 2.9819 - val_loss: 21.7422 - val_mae: 3.3384\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.6017 - mae: 2.9235 - val_loss: 21.4706 - val_mae: 3.3204\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.3226 - mae: 2.9320 - val_loss: 20.8547 - val_mae: 3.3232\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.6061 - mae: 2.9145 - val_loss: 20.6476 - val_mae: 3.3081\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.2017 - mae: 2.8736 - val_loss: 20.3780 - val_mae: 3.2836\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.7556 - mae: 2.8206 - val_loss: 20.1880 - val_mae: 3.2502\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.4670 - mae: 2.7731 - val_loss: 19.9780 - val_mae: 3.2292\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.0900 - mae: 2.7299 - val_loss: 19.8495 - val_mae: 3.1875\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.7875 - mae: 2.6948 - val_loss: 19.6368 - val_mae: 3.1706\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.4615 - mae: 2.6844 - val_loss: 19.2931 - val_mae: 3.1633\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.2040 - mae: 2.6874 - val_loss: 18.9531 - val_mae: 3.1407\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.9285 - mae: 2.6695 - val_loss: 18.7896 - val_mae: 3.1194\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6292 - mae: 2.6490 - val_loss: 18.7092 - val_mae: 3.1214\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.4501 - mae: 2.6176 - val_loss: 18.6917 - val_mae: 3.1087\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.1268 - mae: 2.5765 - val_loss: 18.5469 - val_mae: 3.0904\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.9103 - mae: 2.5576 - val_loss: 18.2934 - val_mae: 3.0722\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7277 - mae: 2.5457 - val_loss: 18.1496 - val_mae: 3.0556\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.4863 - mae: 2.5324 - val_loss: 17.8697 - val_mae: 3.0373\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.3135 - mae: 2.5295 - val_loss: 17.7009 - val_mae: 3.0314\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1866 - mae: 2.5236 - val_loss: 17.5731 - val_mae: 3.0218\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.0124 - mae: 2.4994 - val_loss: 17.5961 - val_mae: 3.0136\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.8016 - mae: 2.4763 - val_loss: 17.3439 - val_mae: 2.9995\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.7150 - mae: 2.4875 - val_loss: 17.1999 - val_mae: 3.0026\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5097 - mae: 2.4681 - val_loss: 17.1489 - val_mae: 2.9804\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.3239 - mae: 2.4412 - val_loss: 17.1561 - val_mae: 2.9668\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.2177 - mae: 2.4330 - val_loss: 16.9921 - val_mae: 2.9698\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.0388 - mae: 2.4245 - val_loss: 16.8628 - val_mae: 2.9627\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9239 - mae: 2.4179 - val_loss: 16.7888 - val_mae: 2.9605\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.7816 - mae: 2.4043 - val_loss: 16.7563 - val_mae: 2.9485\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.7142 - mae: 2.3830 - val_loss: 16.7828 - val_mae: 2.9434\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6815 - mae: 2.3827 - val_loss: 16.5908 - val_mae: 2.9409\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5603 - mae: 2.3723 - val_loss: 16.5710 - val_mae: 2.9391\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3657 - mae: 2.3686 - val_loss: 16.4627 - val_mae: 2.9373\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.2314 - mae: 2.3639 - val_loss: 16.2838 - val_mae: 2.9289\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1213 - mae: 2.3518 - val_loss: 16.2380 - val_mae: 2.9259\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.0288 - mae: 2.3436 - val_loss: 16.2927 - val_mae: 2.9265\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9752 - mae: 2.3390 - val_loss: 16.2636 - val_mae: 2.9232\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8680 - mae: 2.3301 - val_loss: 16.3196 - val_mae: 2.9233\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.7501 - mae: 2.3148 - val_loss: 16.1549 - val_mae: 2.9072\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6859 - mae: 2.3008 - val_loss: 16.0249 - val_mae: 2.9011\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6300 - mae: 2.3073 - val_loss: 15.8919 - val_mae: 2.8963\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5112 - mae: 2.2939 - val_loss: 15.8804 - val_mae: 2.8869\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4343 - mae: 2.2858 - val_loss: 15.8153 - val_mae: 2.8838\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3246 - mae: 2.2806 - val_loss: 15.6623 - val_mae: 2.8800\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3434 - mae: 2.2809 - val_loss: 15.6460 - val_mae: 2.8869\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1814 - mae: 2.2623 - val_loss: 15.7529 - val_mae: 2.8794\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1182 - mae: 2.2455 - val_loss: 15.6759 - val_mae: 2.8628\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0154 - mae: 2.2360 - val_loss: 15.5351 - val_mae: 2.8598\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9813 - mae: 2.2317 - val_loss: 15.3927 - val_mae: 2.8520\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9054 - mae: 2.2232 - val_loss: 15.4884 - val_mae: 2.8485\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8866 - mae: 2.2266 - val_loss: 15.4081 - val_mae: 2.8673\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7779 - mae: 2.2249 - val_loss: 15.3164 - val_mae: 2.8492\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7906 - mae: 2.2133 - val_loss: 15.2636 - val_mae: 2.8242\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6400 - mae: 2.1916 - val_loss: 15.1775 - val_mae: 2.8346\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5546 - mae: 2.1942 - val_loss: 15.1750 - val_mae: 2.8372\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5250 - mae: 2.1912 - val_loss: 14.9681 - val_mae: 2.8166\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4389 - mae: 2.1850 - val_loss: 15.0279 - val_mae: 2.8290\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3877 - mae: 2.1713 - val_loss: 15.0020 - val_mae: 2.8212\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3615 - mae: 2.1629 - val_loss: 14.9305 - val_mae: 2.8039\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3228 - mae: 2.1554 - val_loss: 14.9008 - val_mae: 2.8118\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2910 - mae: 2.1606 - val_loss: 14.9528 - val_mae: 2.8114\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2283 - mae: 2.1501 - val_loss: 14.8084 - val_mae: 2.7860\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1187 - mae: 2.1417 - val_loss: 14.7543 - val_mae: 2.7870\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0664 - mae: 2.1450 - val_loss: 14.6520 - val_mae: 2.7752\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0291 - mae: 2.1377 - val_loss: 14.6643 - val_mae: 2.7827\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0024 - mae: 2.1444 - val_loss: 14.5179 - val_mae: 2.7762\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9418 - mae: 2.1281 - val_loss: 14.6227 - val_mae: 2.7780\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8738 - mae: 2.1225 - val_loss: 14.6592 - val_mae: 2.7838\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8461 - mae: 2.1241 - val_loss: 14.5310 - val_mae: 2.7701\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7603 - mae: 2.1152 - val_loss: 14.5262 - val_mae: 2.7720\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7648 - mae: 2.1077 - val_loss: 14.6521 - val_mae: 2.7804\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6547 - mae: 2.1014 - val_loss: 14.5626 - val_mae: 2.7912\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7046 - mae: 2.1091 - val_loss: 14.5135 - val_mae: 2.7852\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6006 - mae: 2.0964 - val_loss: 14.6609 - val_mae: 2.8044\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5873 - mae: 2.0921 - val_loss: 14.4491 - val_mae: 2.7745\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4906 - mae: 2.0787 - val_loss: 14.3650 - val_mae: 2.7571\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4395 - mae: 2.0717 - val_loss: 14.4424 - val_mae: 2.7739\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3965 - mae: 2.0691 - val_loss: 14.3293 - val_mae: 2.7572\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3361 - mae: 2.0585 - val_loss: 14.3325 - val_mae: 2.7630\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3693 - mae: 2.0699 - val_loss: 14.3860 - val_mae: 2.7867\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2416 - mae: 2.0630 - val_loss: 14.3013 - val_mae: 2.7452\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2451 - mae: 2.0485 - val_loss: 14.3290 - val_mae: 2.7417\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1902 - mae: 2.0467 - val_loss: 14.2801 - val_mae: 2.7654\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1328 - mae: 2.0535 - val_loss: 14.1872 - val_mae: 2.7487\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1053 - mae: 2.0449 - val_loss: 14.1578 - val_mae: 2.7529\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1762 - mae: 2.0595 - val_loss: 14.3155 - val_mae: 2.7651\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0302 - mae: 2.0239 - val_loss: 14.1293 - val_mae: 2.7534\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0044 - mae: 2.0267 - val_loss: 14.0768 - val_mae: 2.7333\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9440 - mae: 2.0244 - val_loss: 13.9942 - val_mae: 2.7328\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8572 - mae: 2.0192 - val_loss: 13.9100 - val_mae: 2.7203\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9738 - mae: 2.0189 - val_loss: 13.9971 - val_mae: 2.7206\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7750 - mae: 2.0090 - val_loss: 13.9049 - val_mae: 2.7217\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7737 - mae: 2.0101 - val_loss: 13.9157 - val_mae: 2.7205\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7329 - mae: 1.9983 - val_loss: 13.8622 - val_mae: 2.7099\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6668 - mae: 1.9906 - val_loss: 13.9386 - val_mae: 2.7265\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7421 - mae: 2.0021 - val_loss: 13.9572 - val_mae: 2.7457\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6287 - mae: 1.9911 - val_loss: 13.8882 - val_mae: 2.7260\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6005 - mae: 1.9903 - val_loss: 14.0350 - val_mae: 2.7457\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5728 - mae: 1.9858 - val_loss: 14.0068 - val_mae: 2.7328\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4724 - mae: 1.9697 - val_loss: 13.8068 - val_mae: 2.7035\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5076 - mae: 1.9741 - val_loss: 13.8763 - val_mae: 2.7316\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3851 - mae: 1.9628 - val_loss: 13.8519 - val_mae: 2.7152\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4097 - mae: 1.9631 - val_loss: 13.7582 - val_mae: 2.6958\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3974 - mae: 1.9586 - val_loss: 13.7468 - val_mae: 2.7072\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3009 - mae: 1.9544 - val_loss: 13.8944 - val_mae: 2.7333\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2986 - mae: 1.9428 - val_loss: 13.8689 - val_mae: 2.7215\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3279 - mae: 1.9429 - val_loss: 13.7951 - val_mae: 2.7051\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1479 - mae: 1.9313 - val_loss: 13.7604 - val_mae: 2.7099\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1974 - mae: 1.9427 - val_loss: 13.7333 - val_mae: 2.7069\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1888 - mae: 1.9387 - val_loss: 13.5501 - val_mae: 2.6828\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0922 - mae: 1.9261 - val_loss: 13.6731 - val_mae: 2.7015\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0804 - mae: 1.9238 - val_loss: 13.5563 - val_mae: 2.6840\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0930 - mae: 1.9182 - val_loss: 13.5556 - val_mae: 2.6720\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0079 - mae: 1.9207 - val_loss: 13.7262 - val_mae: 2.7108\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0360 - mae: 1.9167 - val_loss: 13.8691 - val_mae: 2.7162\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0057 - mae: 1.9174 - val_loss: 13.6467 - val_mae: 2.7109\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9369 - mae: 1.9154 - val_loss: 13.6452 - val_mae: 2.7062\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8669 - mae: 1.8992 - val_loss: 13.5344 - val_mae: 2.6748\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8263 - mae: 1.8945 - val_loss: 13.4577 - val_mae: 2.6741\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7614 - mae: 1.8830 - val_loss: 13.4078 - val_mae: 2.6662\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7725 - mae: 1.8924 - val_loss: 13.4968 - val_mae: 2.6820\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7477 - mae: 1.8931 - val_loss: 13.4679 - val_mae: 2.6770\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7213 - mae: 1.8892 - val_loss: 13.5079 - val_mae: 2.6836\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6465 - mae: 1.8732 - val_loss: 13.4084 - val_mae: 2.6564\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6344 - mae: 1.8659 - val_loss: 13.4219 - val_mae: 2.6733\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6193 - mae: 1.8724 - val_loss: 13.4942 - val_mae: 2.6902\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5769 - mae: 1.8535 - val_loss: 13.4020 - val_mae: 2.6664\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5422 - mae: 1.8489 - val_loss: 13.3639 - val_mae: 2.6718\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5167 - mae: 1.8529 - val_loss: 13.2684 - val_mae: 2.6547\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5824 - mae: 1.8579 - val_loss: 13.4001 - val_mae: 2.6599\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4936 - mae: 1.8511 - val_loss: 13.2893 - val_mae: 2.6503\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4123 - mae: 1.8523 - val_loss: 13.3717 - val_mae: 2.6695\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3548 - mae: 1.8471 - val_loss: 13.4077 - val_mae: 2.6704\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4001 - mae: 1.8453 - val_loss: 13.2549 - val_mae: 2.6460\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4000 - mae: 1.8454 - val_loss: 13.4048 - val_mae: 2.6774\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2846 - mae: 1.8208 - val_loss: 13.2741 - val_mae: 2.6548\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2122 - mae: 1.8186 - val_loss: 13.2733 - val_mae: 2.6586\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1884 - mae: 1.8318 - val_loss: 13.3920 - val_mae: 2.6744\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1287 - mae: 1.8221 - val_loss: 13.2063 - val_mae: 2.6470\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1620 - mae: 1.8116 - val_loss: 13.2769 - val_mae: 2.6590\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1117 - mae: 1.8199 - val_loss: 13.2880 - val_mae: 2.6586\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1034 - mae: 1.8126 - val_loss: 13.1616 - val_mae: 2.6384\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0336 - mae: 1.7944 - val_loss: 13.2594 - val_mae: 2.6494\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0872 - mae: 1.8135 - val_loss: 13.3301 - val_mae: 2.6591\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9986 - mae: 1.7965 - val_loss: 13.2203 - val_mae: 2.6433\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9759 - mae: 1.7873 - val_loss: 13.2569 - val_mae: 2.6476\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9186 - mae: 1.7906 - val_loss: 13.1269 - val_mae: 2.6383\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9004 - mae: 1.7818 - val_loss: 13.0656 - val_mae: 2.6168\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8944 - mae: 1.7765 - val_loss: 13.2698 - val_mae: 2.6467\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8595 - mae: 1.7768 - val_loss: 13.0418 - val_mae: 2.6221\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7800 - mae: 1.7626 - val_loss: 13.1318 - val_mae: 2.6372\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7846 - mae: 1.7586 - val_loss: 12.9978 - val_mae: 2.6231\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7370 - mae: 1.7605 - val_loss: 13.2117 - val_mae: 2.6476\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7131 - mae: 1.7502 - val_loss: 13.0946 - val_mae: 2.6257\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7310 - mae: 1.7521 - val_loss: 12.9840 - val_mae: 2.6174\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7116 - mae: 1.7407 - val_loss: 13.0798 - val_mae: 2.6197\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5857 - mae: 1.7283 - val_loss: 13.1304 - val_mae: 2.6357\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6204 - mae: 1.7590 - val_loss: 13.2626 - val_mae: 2.6510\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5835 - mae: 1.7481 - val_loss: 13.2923 - val_mae: 2.6586\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5293 - mae: 1.7310 - val_loss: 13.0653 - val_mae: 2.6215\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5007 - mae: 1.7232 - val_loss: 13.0033 - val_mae: 2.6146\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4578 - mae: 1.7209 - val_loss: 13.0328 - val_mae: 2.6157\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4378 - mae: 1.7125 - val_loss: 12.9055 - val_mae: 2.6023\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4481 - mae: 1.7078 - val_loss: 13.0818 - val_mae: 2.6256\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3872 - mae: 1.7165 - val_loss: 12.9510 - val_mae: 2.5987\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3668 - mae: 1.7095 - val_loss: 12.9856 - val_mae: 2.6041\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3219 - mae: 1.6988 - val_loss: 12.9449 - val_mae: 2.5995\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2854 - mae: 1.6877 - val_loss: 12.9643 - val_mae: 2.6009\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2676 - mae: 1.6939 - val_loss: 12.8624 - val_mae: 2.5896\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2547 - mae: 1.6877 - val_loss: 12.9100 - val_mae: 2.5930\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2785 - mae: 1.6952 - val_loss: 12.9850 - val_mae: 2.6047\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3615 - mae: 1.6928 - val_loss: 13.1214 - val_mae: 2.6216\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2227 - mae: 1.6868 - val_loss: 13.1338 - val_mae: 2.6261\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2149 - mae: 1.6853 - val_loss: 12.9791 - val_mae: 2.5987\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1565 - mae: 1.6675 - val_loss: 13.1970 - val_mae: 2.6453\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0905 - mae: 1.6628 - val_loss: 12.9367 - val_mae: 2.6008\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0536 - mae: 1.6559 - val_loss: 13.0363 - val_mae: 2.6091\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0388 - mae: 1.6505 - val_loss: 13.0199 - val_mae: 2.6100\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9938 - mae: 1.6462 - val_loss: 12.9833 - val_mae: 2.6044\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0107 - mae: 1.6524 - val_loss: 12.9178 - val_mae: 2.6013\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0053 - mae: 1.6399 - val_loss: 13.0210 - val_mae: 2.6048\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9561 - mae: 1.6371 - val_loss: 13.0346 - val_mae: 2.6031\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9458 - mae: 1.6453 - val_loss: 13.0144 - val_mae: 2.6079\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8685 - mae: 1.6295 - val_loss: 12.9809 - val_mae: 2.6028\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0184 - mae: 1.6408 - val_loss: 12.9244 - val_mae: 2.5934\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8457 - mae: 1.6491 - val_loss: 13.1725 - val_mae: 2.6504\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9249 - mae: 1.6520 - val_loss: 12.8171 - val_mae: 2.5898\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8795 - mae: 1.6347 - val_loss: 12.7679 - val_mae: 2.5732\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8759 - mae: 1.6530 - val_loss: 13.0706 - val_mae: 2.6342\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7525 - mae: 1.6273 - val_loss: 12.8163 - val_mae: 2.5730\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7825 - mae: 1.6263 - val_loss: 12.9827 - val_mae: 2.5951\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7018 - mae: 1.6152 - val_loss: 13.2456 - val_mae: 2.6448\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6795 - mae: 1.6094 - val_loss: 13.1096 - val_mae: 2.6187\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7432 - mae: 1.6015 - val_loss: 12.9208 - val_mae: 2.5851\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6768 - mae: 1.6043 - val_loss: 13.2949 - val_mae: 2.6525\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6262 - mae: 1.6075 - val_loss: 12.9323 - val_mae: 2.5832\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5955 - mae: 1.5884 - val_loss: 12.9895 - val_mae: 2.5998\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6243 - mae: 1.5985 - val_loss: 13.0085 - val_mae: 2.5958\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5274 - mae: 1.5739 - val_loss: 13.0294 - val_mae: 2.6100\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5290 - mae: 1.5833 - val_loss: 13.0707 - val_mae: 2.6231\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4963 - mae: 1.5728 - val_loss: 12.9489 - val_mae: 2.6034\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5001 - mae: 1.5763 - val_loss: 12.8592 - val_mae: 2.5791\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4421 - mae: 1.5681 - val_loss: 13.0640 - val_mae: 2.6172\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4543 - mae: 1.5639 - val_loss: 12.9528 - val_mae: 2.5986\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4076 - mae: 1.5627 - val_loss: 13.1040 - val_mae: 2.6151\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3910 - mae: 1.5603 - val_loss: 13.1012 - val_mae: 2.6262\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3931 - mae: 1.5623 - val_loss: 13.1102 - val_mae: 2.6249\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3285 - mae: 1.5422 - val_loss: 12.7919 - val_mae: 2.5706\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3198 - mae: 1.5405 - val_loss: 12.9343 - val_mae: 2.6046\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3281 - mae: 1.5340 - val_loss: 12.9494 - val_mae: 2.5952\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2634 - mae: 1.5304 - val_loss: 12.9357 - val_mae: 2.5927\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3179 - mae: 1.5616 - val_loss: 13.0323 - val_mae: 2.6242\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2987 - mae: 1.5252 - val_loss: 12.8802 - val_mae: 2.5843\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2211 - mae: 1.5279 - val_loss: 12.9769 - val_mae: 2.6008\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2197 - mae: 1.5297 - val_loss: 12.9559 - val_mae: 2.6040\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1850 - mae: 1.5255 - val_loss: 13.0659 - val_mae: 2.6142\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2132 - mae: 1.5186 - val_loss: 13.3961 - val_mae: 2.6801\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1460 - mae: 1.5232 - val_loss: 12.9450 - val_mae: 2.5956\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1134 - mae: 1.5075 - val_loss: 12.9797 - val_mae: 2.6101\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0665 - mae: 1.4985 - val_loss: 13.0094 - val_mae: 2.6244\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0327 - mae: 1.4975 - val_loss: 12.9080 - val_mae: 2.6066\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0179 - mae: 1.4917 - val_loss: 12.9742 - val_mae: 2.6190\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9975 - mae: 1.4933 - val_loss: 12.9643 - val_mae: 2.6126\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9972 - mae: 1.4845 - val_loss: 12.9386 - val_mae: 2.6054\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0304 - mae: 1.4922 - val_loss: 13.0669 - val_mae: 2.6403\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9325 - mae: 1.4659 - val_loss: 12.8292 - val_mae: 2.5827\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9476 - mae: 1.4771 - val_loss: 13.0340 - val_mae: 2.6171\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9378 - mae: 1.4829 - val_loss: 13.0483 - val_mae: 2.6432\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9539 - mae: 1.4695 - val_loss: 12.7740 - val_mae: 2.5839\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8773 - mae: 1.4571 - val_loss: 13.0517 - val_mae: 2.6467\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8884 - mae: 1.4710 - val_loss: 12.9185 - val_mae: 2.6133\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8821 - mae: 1.4564 - val_loss: 12.9247 - val_mae: 2.6187\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8016 - mae: 1.4453 - val_loss: 13.0125 - val_mae: 2.6345\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8275 - mae: 1.4694 - val_loss: 12.9592 - val_mae: 2.6312\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7792 - mae: 1.4302 - val_loss: 13.0023 - val_mae: 2.6334\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7352 - mae: 1.4250 - val_loss: 13.0402 - val_mae: 2.6335\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7883 - mae: 1.4625 - val_loss: 12.9447 - val_mae: 2.6166\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8045 - mae: 1.4400 - val_loss: 13.0071 - val_mae: 2.6356\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6879 - mae: 1.4279 - val_loss: 13.2038 - val_mae: 2.6639\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6769 - mae: 1.4212 - val_loss: 12.7823 - val_mae: 2.5949\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6900 - mae: 1.4052 - val_loss: 13.0455 - val_mae: 2.6442\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7618 - mae: 1.4683 - val_loss: 13.0829 - val_mae: 2.6508\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6597 - mae: 1.4003 - val_loss: 12.8636 - val_mae: 2.6084\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6620 - mae: 1.4276 - val_loss: 13.2306 - val_mae: 2.6645\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.6509 - mae: 1.4192 - val_loss: 12.9574 - val_mae: 2.6159\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6280 - mae: 1.4233 - val_loss: 13.0153 - val_mae: 2.6467\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5618 - mae: 1.4049 - val_loss: 12.8591 - val_mae: 2.5994\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5275 - mae: 1.3874 - val_loss: 13.0022 - val_mae: 2.6426\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5968 - mae: 1.4166 - val_loss: 13.1552 - val_mae: 2.6582\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4762 - mae: 1.3846 - val_loss: 13.0094 - val_mae: 2.6282\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5127 - mae: 1.3791 - val_loss: 13.1208 - val_mae: 2.6371\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4940 - mae: 1.3927 - val_loss: 13.1554 - val_mae: 2.6589\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5695 - mae: 1.4071 - val_loss: 13.0927 - val_mae: 2.6539\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5283 - mae: 1.3927 - val_loss: 12.8931 - val_mae: 2.6040\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5039 - mae: 1.4090 - val_loss: 13.1836 - val_mae: 2.6715\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4793 - mae: 1.3827 - val_loss: 12.8711 - val_mae: 2.6091\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5327 - mae: 1.3882 - val_loss: 12.7833 - val_mae: 2.5920\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6450 - mae: 1.4542 - val_loss: 13.2539 - val_mae: 2.6924\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4483 - mae: 1.3754 - val_loss: 12.9368 - val_mae: 2.6175\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3486 - mae: 1.3727 - val_loss: 13.3245 - val_mae: 2.6868\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3868 - mae: 1.3688 - val_loss: 12.8680 - val_mae: 2.6140\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3706 - mae: 1.3396 - val_loss: 12.9841 - val_mae: 2.6410\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3885 - mae: 1.3644 - val_loss: 12.8699 - val_mae: 2.6166\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3110 - mae: 1.3467 - val_loss: 13.0548 - val_mae: 2.6503\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3104 - mae: 1.3607 - val_loss: 12.9622 - val_mae: 2.6274\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2728 - mae: 1.3381 - val_loss: 13.2179 - val_mae: 2.6760\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2702 - mae: 1.3443 - val_loss: 13.0241 - val_mae: 2.6353\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2380 - mae: 1.3406 - val_loss: 13.1961 - val_mae: 2.6712\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2417 - mae: 1.3379 - val_loss: 13.1365 - val_mae: 2.6619\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2053 - mae: 1.3221 - val_loss: 12.9650 - val_mae: 2.6310\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1965 - mae: 1.3288 - val_loss: 13.1255 - val_mae: 2.6542\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2001 - mae: 1.3412 - val_loss: 13.2138 - val_mae: 2.6665\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2681 - mae: 1.3343 - val_loss: 13.2634 - val_mae: 2.6754\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 9.8723 - mae: 2.1575\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 24ms/step - loss: 536.5832 - mae: 21.3481 - val_loss: 624.7267 - val_mae: 23.0844\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 511.0669 - mae: 20.7209 - val_loss: 595.7029 - val_mae: 22.4431\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 484.4568 - mae: 20.0252 - val_loss: 562.3790 - val_mae: 21.6872\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 452.6116 - mae: 19.1881 - val_loss: 520.5115 - val_mae: 20.7275\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 413.8696 - mae: 18.1514 - val_loss: 469.8328 - val_mae: 19.5475\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 369.5377 - mae: 16.9156 - val_loss: 411.1682 - val_mae: 18.1235\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 318.8761 - mae: 15.4975 - val_loss: 346.1827 - val_mae: 16.4367\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 263.4843 - mae: 13.8897 - val_loss: 277.0734 - val_mae: 14.4249\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 208.0408 - mae: 12.1263 - val_loss: 209.3782 - val_mae: 12.1378\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 155.6863 - mae: 10.2245 - val_loss: 153.4581 - val_mae: 9.9296\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 113.9216 - mae: 8.5688 - val_loss: 115.0208 - val_mae: 8.2161\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 85.1279 - mae: 7.3719 - val_loss: 93.0855 - val_mae: 7.1104\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 67.5176 - mae: 6.3960 - val_loss: 79.3426 - val_mae: 6.4402\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 55.4187 - mae: 5.6829 - val_loss: 68.7778 - val_mae: 5.8698\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 46.7713 - mae: 5.0829 - val_loss: 58.9584 - val_mae: 5.3138\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39.5091 - mae: 4.6166 - val_loss: 50.8631 - val_mae: 4.8220\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 33.6252 - mae: 4.2385 - val_loss: 45.6691 - val_mae: 4.4922\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 30.3104 - mae: 3.9871 - val_loss: 41.7234 - val_mae: 4.2291\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27.5569 - mae: 3.7740 - val_loss: 39.0541 - val_mae: 4.0388\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25.8840 - mae: 3.6486 - val_loss: 37.1205 - val_mae: 3.8884\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.6894 - mae: 3.5426 - val_loss: 35.3426 - val_mae: 3.7565\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.7474 - mae: 3.4807 - val_loss: 33.7849 - val_mae: 3.6664\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.9108 - mae: 3.4261 - val_loss: 32.8030 - val_mae: 3.5805\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.2281 - mae: 3.3684 - val_loss: 31.9623 - val_mae: 3.5148\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.6439 - mae: 3.3186 - val_loss: 31.1964 - val_mae: 3.4648\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.0521 - mae: 3.2755 - val_loss: 30.1192 - val_mae: 3.4172\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.5559 - mae: 3.2532 - val_loss: 29.3655 - val_mae: 3.3753\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.0371 - mae: 3.2073 - val_loss: 28.8635 - val_mae: 3.3212\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.6335 - mae: 3.1627 - val_loss: 28.4100 - val_mae: 3.2863\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.1189 - mae: 3.1242 - val_loss: 27.6496 - val_mae: 3.2461\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.6745 - mae: 3.1056 - val_loss: 26.8427 - val_mae: 3.2178\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.3131 - mae: 3.0922 - val_loss: 26.2508 - val_mae: 3.1678\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.8147 - mae: 3.0433 - val_loss: 25.8882 - val_mae: 3.1399\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.4238 - mae: 2.9946 - val_loss: 25.6391 - val_mae: 3.1110\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.0856 - mae: 2.9523 - val_loss: 25.1834 - val_mae: 3.0858\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.7156 - mae: 2.9323 - val_loss: 24.5721 - val_mae: 3.0818\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.3305 - mae: 2.9056 - val_loss: 24.2168 - val_mae: 3.0573\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.0709 - mae: 2.8828 - val_loss: 23.7338 - val_mae: 3.0600\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.6905 - mae: 2.8592 - val_loss: 23.2939 - val_mae: 3.0175\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.3996 - mae: 2.8386 - val_loss: 22.8993 - val_mae: 3.0152\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.0738 - mae: 2.8042 - val_loss: 22.6370 - val_mae: 2.9980\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.7687 - mae: 2.7764 - val_loss: 22.2545 - val_mae: 2.9772\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.4461 - mae: 2.7471 - val_loss: 22.0624 - val_mae: 2.9642\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.2222 - mae: 2.7165 - val_loss: 21.9242 - val_mae: 2.9656\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9546 - mae: 2.7003 - val_loss: 21.5897 - val_mae: 2.9468\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7516 - mae: 2.6904 - val_loss: 21.3240 - val_mae: 2.9132\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5006 - mae: 2.6704 - val_loss: 21.1412 - val_mae: 2.9016\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2753 - mae: 2.6427 - val_loss: 21.0392 - val_mae: 2.9016\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1010 - mae: 2.6146 - val_loss: 20.9504 - val_mae: 2.9082\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9242 - mae: 2.5872 - val_loss: 20.7831 - val_mae: 2.8889\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.7657 - mae: 2.5717 - val_loss: 20.5487 - val_mae: 2.8657\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.5593 - mae: 2.5669 - val_loss: 20.3608 - val_mae: 2.8488\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3828 - mae: 2.5533 - val_loss: 20.2223 - val_mae: 2.8469\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.2256 - mae: 2.5492 - val_loss: 20.1042 - val_mae: 2.8427\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1106 - mae: 2.5271 - val_loss: 20.0743 - val_mae: 2.8342\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.9185 - mae: 2.5014 - val_loss: 20.0185 - val_mae: 2.8399\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.8673 - mae: 2.5095 - val_loss: 19.9160 - val_mae: 2.8400\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.7325 - mae: 2.5135 - val_loss: 19.6766 - val_mae: 2.7979\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5484 - mae: 2.4792 - val_loss: 19.7268 - val_mae: 2.8141\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3893 - mae: 2.4500 - val_loss: 19.6327 - val_mae: 2.8100\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2664 - mae: 2.4401 - val_loss: 19.5326 - val_mae: 2.7957\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.1491 - mae: 2.4352 - val_loss: 19.4722 - val_mae: 2.7921\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0605 - mae: 2.4137 - val_loss: 19.4656 - val_mae: 2.7953\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9826 - mae: 2.4106 - val_loss: 19.4970 - val_mae: 2.8120\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8109 - mae: 2.3997 - val_loss: 19.3716 - val_mae: 2.7875\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8075 - mae: 2.4079 - val_loss: 19.3082 - val_mae: 2.7744\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8148 - mae: 2.4158 - val_loss: 19.3694 - val_mae: 2.8002\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5708 - mae: 2.3691 - val_loss: 19.3281 - val_mae: 2.7794\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4856 - mae: 2.3498 - val_loss: 19.2147 - val_mae: 2.7612\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3773 - mae: 2.3464 - val_loss: 19.2091 - val_mae: 2.7669\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3229 - mae: 2.3408 - val_loss: 19.2789 - val_mae: 2.7862\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2363 - mae: 2.3329 - val_loss: 19.1937 - val_mae: 2.7760\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1819 - mae: 2.3224 - val_loss: 19.1369 - val_mae: 2.7582\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1195 - mae: 2.3106 - val_loss: 19.1642 - val_mae: 2.7768\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0136 - mae: 2.3016 - val_loss: 19.0539 - val_mae: 2.7505\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0106 - mae: 2.2976 - val_loss: 19.1189 - val_mae: 2.7734\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0753 - mae: 2.2840 - val_loss: 19.0482 - val_mae: 2.7466\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8238 - mae: 2.2893 - val_loss: 19.2462 - val_mae: 2.8068\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8782 - mae: 2.3071 - val_loss: 19.1277 - val_mae: 2.7840\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7307 - mae: 2.2840 - val_loss: 19.1342 - val_mae: 2.7909\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6455 - mae: 2.2555 - val_loss: 19.0957 - val_mae: 2.7832\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5420 - mae: 2.2379 - val_loss: 19.0613 - val_mae: 2.7812\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5395 - mae: 2.2425 - val_loss: 19.0756 - val_mae: 2.7893\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4429 - mae: 2.2294 - val_loss: 18.8978 - val_mae: 2.7605\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3739 - mae: 2.2214 - val_loss: 18.9060 - val_mae: 2.7653\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3021 - mae: 2.2108 - val_loss: 19.0068 - val_mae: 2.7802\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3291 - mae: 2.2097 - val_loss: 18.9090 - val_mae: 2.7501\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3462 - mae: 2.2083 - val_loss: 19.1004 - val_mae: 2.7889\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2031 - mae: 2.1997 - val_loss: 18.9527 - val_mae: 2.7608\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1274 - mae: 2.1765 - val_loss: 18.8547 - val_mae: 2.7461\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0865 - mae: 2.1785 - val_loss: 18.9531 - val_mae: 2.7681\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0984 - mae: 2.1641 - val_loss: 18.9025 - val_mae: 2.7617\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9766 - mae: 2.1727 - val_loss: 18.7803 - val_mae: 2.7494\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9732 - mae: 2.1824 - val_loss: 18.8273 - val_mae: 2.7645\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0153 - mae: 2.1626 - val_loss: 18.8340 - val_mae: 2.7753\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8029 - mae: 2.1377 - val_loss: 18.7360 - val_mae: 2.7640\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8500 - mae: 2.1654 - val_loss: 18.6456 - val_mae: 2.7549\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7450 - mae: 2.1453 - val_loss: 18.6570 - val_mae: 2.7552\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6980 - mae: 2.1191 - val_loss: 18.6789 - val_mae: 2.7496\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6493 - mae: 2.1156 - val_loss: 18.6405 - val_mae: 2.7396\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6519 - mae: 2.1243 - val_loss: 18.5463 - val_mae: 2.7258\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5861 - mae: 2.1125 - val_loss: 18.4966 - val_mae: 2.7203\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 8.5293 - mae: 2.1019 - val_loss: 18.5336 - val_mae: 2.7257\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.5164 - mae: 2.0972 - val_loss: 18.6718 - val_mae: 2.7443\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 8.4722 - mae: 2.1003 - val_loss: 18.5411 - val_mae: 2.7251\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.4102 - mae: 2.0814 - val_loss: 18.5663 - val_mae: 2.7283\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.4154 - mae: 2.0752 - val_loss: 18.5334 - val_mae: 2.7251\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.3762 - mae: 2.0687 - val_loss: 18.4580 - val_mae: 2.7141\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.3026 - mae: 2.0801 - val_loss: 18.5679 - val_mae: 2.7379\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.4230 - mae: 2.0879 - val_loss: 18.4782 - val_mae: 2.7308\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.3774 - mae: 2.0688 - val_loss: 18.8365 - val_mae: 2.7883\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.2355 - mae: 2.0550 - val_loss: 18.5781 - val_mae: 2.7411\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2264 - mae: 2.0606 - val_loss: 18.4361 - val_mae: 2.7162\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1585 - mae: 2.0546 - val_loss: 18.4434 - val_mae: 2.7225\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0952 - mae: 2.0423 - val_loss: 18.4310 - val_mae: 2.7147\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0784 - mae: 2.0265 - val_loss: 18.3940 - val_mae: 2.7116\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1658 - mae: 2.0472 - val_loss: 18.4577 - val_mae: 2.7312\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9901 - mae: 2.0183 - val_loss: 18.3985 - val_mae: 2.7186\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9879 - mae: 2.0146 - val_loss: 18.2838 - val_mae: 2.6961\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9451 - mae: 2.0048 - val_loss: 18.4813 - val_mae: 2.7170\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9095 - mae: 2.0046 - val_loss: 18.5684 - val_mae: 2.7241\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8610 - mae: 2.0002 - val_loss: 18.3912 - val_mae: 2.7037\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8990 - mae: 2.0091 - val_loss: 18.2534 - val_mae: 2.6878\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8621 - mae: 2.0126 - val_loss: 18.5084 - val_mae: 2.7304\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7793 - mae: 1.9972 - val_loss: 18.4776 - val_mae: 2.7304\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7392 - mae: 1.9708 - val_loss: 18.3036 - val_mae: 2.7096\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7148 - mae: 1.9701 - val_loss: 18.1602 - val_mae: 2.6951\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6736 - mae: 1.9739 - val_loss: 18.1739 - val_mae: 2.6959\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6387 - mae: 1.9780 - val_loss: 18.3821 - val_mae: 2.7388\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5838 - mae: 1.9751 - val_loss: 18.2657 - val_mae: 2.7122\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5783 - mae: 1.9649 - val_loss: 18.3350 - val_mae: 2.7154\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5830 - mae: 1.9571 - val_loss: 18.4442 - val_mae: 2.7182\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4566 - mae: 1.9468 - val_loss: 18.2674 - val_mae: 2.7087\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4512 - mae: 1.9280 - val_loss: 18.1488 - val_mae: 2.6866\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4289 - mae: 1.9309 - val_loss: 18.1224 - val_mae: 2.6890\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3998 - mae: 1.9370 - val_loss: 18.1537 - val_mae: 2.6916\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4135 - mae: 1.9464 - val_loss: 18.1030 - val_mae: 2.6792\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3098 - mae: 1.9225 - val_loss: 18.0799 - val_mae: 2.6696\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3200 - mae: 1.9203 - val_loss: 18.0312 - val_mae: 2.6731\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2865 - mae: 1.9064 - val_loss: 18.1265 - val_mae: 2.6787\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2119 - mae: 1.9028 - val_loss: 17.8901 - val_mae: 2.6586\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1673 - mae: 1.9023 - val_loss: 17.8236 - val_mae: 2.6499\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1122 - mae: 1.8856 - val_loss: 17.7949 - val_mae: 2.6602\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0932 - mae: 1.8874 - val_loss: 17.9371 - val_mae: 2.6676\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1056 - mae: 1.8965 - val_loss: 18.1081 - val_mae: 2.6837\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0366 - mae: 1.8772 - val_loss: 17.9817 - val_mae: 2.6625\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0687 - mae: 1.8566 - val_loss: 18.0025 - val_mae: 2.6557\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0249 - mae: 1.8600 - val_loss: 17.7875 - val_mae: 2.6525\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9335 - mae: 1.8570 - val_loss: 17.7920 - val_mae: 2.6596\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0664 - mae: 1.8919 - val_loss: 18.1004 - val_mae: 2.6945\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8902 - mae: 1.8625 - val_loss: 17.9848 - val_mae: 2.6657\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9227 - mae: 1.8416 - val_loss: 17.8714 - val_mae: 2.6457\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9203 - mae: 1.8634 - val_loss: 17.7505 - val_mae: 2.6612\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8429 - mae: 1.8595 - val_loss: 17.8438 - val_mae: 2.6564\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7723 - mae: 1.8376 - val_loss: 17.8048 - val_mae: 2.6542\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7644 - mae: 1.8165 - val_loss: 17.8107 - val_mae: 2.6475\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7363 - mae: 1.8302 - val_loss: 17.8477 - val_mae: 2.6737\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7756 - mae: 1.8548 - val_loss: 17.7193 - val_mae: 2.6494\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6308 - mae: 1.8179 - val_loss: 17.9459 - val_mae: 2.6615\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6132 - mae: 1.8056 - val_loss: 17.7399 - val_mae: 2.6422\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6202 - mae: 1.8057 - val_loss: 17.6800 - val_mae: 2.6324\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6585 - mae: 1.8281 - val_loss: 17.6862 - val_mae: 2.6486\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5309 - mae: 1.8090 - val_loss: 17.7562 - val_mae: 2.6545\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5257 - mae: 1.7847 - val_loss: 17.7374 - val_mae: 2.6446\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5407 - mae: 1.7914 - val_loss: 17.6142 - val_mae: 2.6468\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5292 - mae: 1.7859 - val_loss: 17.8175 - val_mae: 2.6654\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4909 - mae: 1.7877 - val_loss: 17.6537 - val_mae: 2.6557\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5257 - mae: 1.7597 - val_loss: 17.6309 - val_mae: 2.6337\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4116 - mae: 1.7791 - val_loss: 17.8624 - val_mae: 2.6766\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4636 - mae: 1.8085 - val_loss: 17.5311 - val_mae: 2.6358\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3942 - mae: 1.7657 - val_loss: 17.5428 - val_mae: 2.6221\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3476 - mae: 1.7688 - val_loss: 17.8125 - val_mae: 2.6743\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3098 - mae: 1.7791 - val_loss: 17.5718 - val_mae: 2.6574\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2751 - mae: 1.7698 - val_loss: 17.5003 - val_mae: 2.6426\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2493 - mae: 1.7399 - val_loss: 17.7181 - val_mae: 2.6674\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2226 - mae: 1.7289 - val_loss: 17.6089 - val_mae: 2.6464\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1625 - mae: 1.7427 - val_loss: 17.6047 - val_mae: 2.6521\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1174 - mae: 1.7341 - val_loss: 17.6753 - val_mae: 2.6511\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1390 - mae: 1.7218 - val_loss: 17.6881 - val_mae: 2.6590\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1245 - mae: 1.7345 - val_loss: 17.4979 - val_mae: 2.6520\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0598 - mae: 1.7368 - val_loss: 17.7797 - val_mae: 2.6690\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0277 - mae: 1.7139 - val_loss: 17.8472 - val_mae: 2.6772\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0435 - mae: 1.7002 - val_loss: 17.5732 - val_mae: 2.6440\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9462 - mae: 1.7065 - val_loss: 17.6887 - val_mae: 2.6615\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9538 - mae: 1.7240 - val_loss: 17.7044 - val_mae: 2.6719\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9388 - mae: 1.6966 - val_loss: 17.6740 - val_mae: 2.6638\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8908 - mae: 1.6821 - val_loss: 17.6122 - val_mae: 2.6606\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8651 - mae: 1.6944 - val_loss: 17.5091 - val_mae: 2.6582\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8315 - mae: 1.7006 - val_loss: 17.6665 - val_mae: 2.6715\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8537 - mae: 1.6858 - val_loss: 17.4889 - val_mae: 2.6512\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8556 - mae: 1.6976 - val_loss: 17.5895 - val_mae: 2.6691\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9124 - mae: 1.6907 - val_loss: 17.7050 - val_mae: 2.6813\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8586 - mae: 1.6881 - val_loss: 17.5687 - val_mae: 2.6712\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8936 - mae: 1.6769 - val_loss: 17.5111 - val_mae: 2.6496\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7266 - mae: 1.6591 - val_loss: 17.5330 - val_mae: 2.6586\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7184 - mae: 1.6526 - val_loss: 17.5725 - val_mae: 2.6583\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6325 - mae: 1.6455 - val_loss: 17.4508 - val_mae: 2.6491\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6700 - mae: 1.6789 - val_loss: 17.4461 - val_mae: 2.6595\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6951 - mae: 1.6479 - val_loss: 17.5764 - val_mae: 2.6731\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5775 - mae: 1.6386 - val_loss: 17.3856 - val_mae: 2.6491\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6080 - mae: 1.6621 - val_loss: 17.4558 - val_mae: 2.6536\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5456 - mae: 1.6374 - val_loss: 17.4575 - val_mae: 2.6524\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6255 - mae: 1.6104 - val_loss: 17.3997 - val_mae: 2.6353\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6104 - mae: 1.6844 - val_loss: 17.8131 - val_mae: 2.6932\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6919 - mae: 1.6941 - val_loss: 17.7055 - val_mae: 2.6876\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8467 - mae: 1.6695 - val_loss: 17.3882 - val_mae: 2.6575\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4299 - mae: 1.6167 - val_loss: 17.3921 - val_mae: 2.6741\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5062 - mae: 1.6498 - val_loss: 17.4524 - val_mae: 2.6783\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5332 - mae: 1.6156 - val_loss: 17.2908 - val_mae: 2.6397\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4158 - mae: 1.6180 - val_loss: 17.3807 - val_mae: 2.6577\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3486 - mae: 1.6245 - val_loss: 17.2821 - val_mae: 2.6388\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3555 - mae: 1.6045 - val_loss: 17.2830 - val_mae: 2.6516\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3018 - mae: 1.5840 - val_loss: 17.3341 - val_mae: 2.6578\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2585 - mae: 1.5998 - val_loss: 17.3081 - val_mae: 2.6539\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2342 - mae: 1.5971 - val_loss: 17.3729 - val_mae: 2.6506\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3471 - mae: 1.6024 - val_loss: 17.5207 - val_mae: 2.6746\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2272 - mae: 1.5867 - val_loss: 17.1692 - val_mae: 2.6468\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2428 - mae: 1.6046 - val_loss: 17.3165 - val_mae: 2.6711\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1315 - mae: 1.5667 - val_loss: 17.2700 - val_mae: 2.6629\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1621 - mae: 1.5754 - val_loss: 17.1583 - val_mae: 2.6540\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1225 - mae: 1.5669 - val_loss: 17.1383 - val_mae: 2.6564\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1097 - mae: 1.5631 - val_loss: 17.3380 - val_mae: 2.6717\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1559 - mae: 1.5741 - val_loss: 17.1699 - val_mae: 2.6420\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0810 - mae: 1.5959 - val_loss: 17.2146 - val_mae: 2.6629\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0003 - mae: 1.5668 - val_loss: 17.2096 - val_mae: 2.6662\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9772 - mae: 1.5572 - val_loss: 17.2508 - val_mae: 2.6652\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9649 - mae: 1.5537 - val_loss: 17.3808 - val_mae: 2.6765\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9146 - mae: 1.5430 - val_loss: 17.3258 - val_mae: 2.6669\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0074 - mae: 1.5337 - val_loss: 17.1850 - val_mae: 2.6548\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8839 - mae: 1.5291 - val_loss: 17.2669 - val_mae: 2.6682\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9042 - mae: 1.5571 - val_loss: 17.2511 - val_mae: 2.6612\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8546 - mae: 1.5300 - val_loss: 17.3023 - val_mae: 2.6684\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8715 - mae: 1.5169 - val_loss: 17.2294 - val_mae: 2.6583\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8510 - mae: 1.5415 - val_loss: 17.1315 - val_mae: 2.6575\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8753 - mae: 1.5285 - val_loss: 16.9871 - val_mae: 2.6471\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7842 - mae: 1.5106 - val_loss: 16.9866 - val_mae: 2.6505\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7903 - mae: 1.5326 - val_loss: 17.1213 - val_mae: 2.6539\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6922 - mae: 1.5102 - val_loss: 17.0074 - val_mae: 2.6509\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8261 - mae: 1.5221 - val_loss: 17.1000 - val_mae: 2.6639\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6998 - mae: 1.5089 - val_loss: 16.9436 - val_mae: 2.6563\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6935 - mae: 1.5199 - val_loss: 17.1160 - val_mae: 2.6850\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6641 - mae: 1.5296 - val_loss: 17.0420 - val_mae: 2.6658\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6895 - mae: 1.4922 - val_loss: 17.1446 - val_mae: 2.6622\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6582 - mae: 1.4956 - val_loss: 17.2096 - val_mae: 2.6624\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6677 - mae: 1.5425 - val_loss: 16.8543 - val_mae: 2.6452\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6451 - mae: 1.4941 - val_loss: 16.9508 - val_mae: 2.6520\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5719 - mae: 1.4918 - val_loss: 16.9985 - val_mae: 2.6656\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5453 - mae: 1.5053 - val_loss: 16.9152 - val_mae: 2.6614\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5031 - mae: 1.4729 - val_loss: 17.0271 - val_mae: 2.6643\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5283 - mae: 1.4709 - val_loss: 16.9838 - val_mae: 2.6571\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4845 - mae: 1.4782 - val_loss: 17.0359 - val_mae: 2.6651\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4907 - mae: 1.4920 - val_loss: 17.0037 - val_mae: 2.6676\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5382 - mae: 1.4802 - val_loss: 16.8754 - val_mae: 2.6534\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5873 - mae: 1.5068 - val_loss: 16.8802 - val_mae: 2.6660\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4515 - mae: 1.4914 - val_loss: 16.9335 - val_mae: 2.6671\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3535 - mae: 1.4468 - val_loss: 16.9580 - val_mae: 2.6661\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4366 - mae: 1.5049 - val_loss: 17.0396 - val_mae: 2.6762\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3257 - mae: 1.4400 - val_loss: 16.9121 - val_mae: 2.6559\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3224 - mae: 1.4265 - val_loss: 16.9350 - val_mae: 2.6510\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4169 - mae: 1.4951 - val_loss: 17.0805 - val_mae: 2.6770\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2792 - mae: 1.4542 - val_loss: 16.9209 - val_mae: 2.6611\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3043 - mae: 1.4491 - val_loss: 17.0397 - val_mae: 2.6768\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3160 - mae: 1.4373 - val_loss: 16.8955 - val_mae: 2.6596\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3218 - mae: 1.4675 - val_loss: 17.1282 - val_mae: 2.6850\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2591 - mae: 1.4403 - val_loss: 16.8852 - val_mae: 2.6639\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2069 - mae: 1.4192 - val_loss: 16.8913 - val_mae: 2.6643\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1802 - mae: 1.4383 - val_loss: 16.8755 - val_mae: 2.6596\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1373 - mae: 1.4254 - val_loss: 16.7230 - val_mae: 2.6539\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1390 - mae: 1.4366 - val_loss: 16.6128 - val_mae: 2.6563\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1638 - mae: 1.4259 - val_loss: 16.6945 - val_mae: 2.6525\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0915 - mae: 1.4304 - val_loss: 16.8029 - val_mae: 2.6629\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1681 - mae: 1.4343 - val_loss: 16.8549 - val_mae: 2.6688\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1012 - mae: 1.4150 - val_loss: 16.7065 - val_mae: 2.6644\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1060 - mae: 1.4144 - val_loss: 16.6385 - val_mae: 2.6623\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1406 - mae: 1.4285 - val_loss: 16.7918 - val_mae: 2.6597\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0593 - mae: 1.4127 - val_loss: 16.6306 - val_mae: 2.6361\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0366 - mae: 1.4006 - val_loss: 16.8020 - val_mae: 2.6663\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0414 - mae: 1.3976 - val_loss: 16.5805 - val_mae: 2.6595\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0151 - mae: 1.3891 - val_loss: 16.7591 - val_mae: 2.6653\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9887 - mae: 1.3949 - val_loss: 16.8559 - val_mae: 2.6595\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9915 - mae: 1.3860 - val_loss: 16.7993 - val_mae: 2.6531\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9315 - mae: 1.4008 - val_loss: 16.6342 - val_mae: 2.6635\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9550 - mae: 1.3907 - val_loss: 16.5800 - val_mae: 2.6550\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9127 - mae: 1.3908 - val_loss: 16.5991 - val_mae: 2.6548\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9695 - mae: 1.4005 - val_loss: 16.4970 - val_mae: 2.6530\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8932 - mae: 1.3712 - val_loss: 16.5329 - val_mae: 2.6520\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9145 - mae: 1.4087 - val_loss: 16.6478 - val_mae: 2.6527\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8099 - mae: 1.3654 - val_loss: 16.7422 - val_mae: 2.6652\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8696 - mae: 1.3726 - val_loss: 16.4959 - val_mae: 2.6537\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8294 - mae: 1.3911 - val_loss: 16.4583 - val_mae: 2.6511\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8413 - mae: 1.3565 - val_loss: 16.3697 - val_mae: 2.6468\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7730 - mae: 1.3696 - val_loss: 16.6149 - val_mae: 2.6599\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7626 - mae: 1.3676 - val_loss: 16.5900 - val_mae: 2.6522\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7750 - mae: 1.3488 - val_loss: 16.6067 - val_mae: 2.6533\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8037 - mae: 1.3967 - val_loss: 16.8727 - val_mae: 2.6803\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7204 - mae: 1.3510 - val_loss: 16.4875 - val_mae: 2.6649\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6916 - mae: 1.3434 - val_loss: 16.5194 - val_mae: 2.6577\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6649 - mae: 1.3453 - val_loss: 16.4100 - val_mae: 2.6447\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7104 - mae: 1.3589 - val_loss: 16.5116 - val_mae: 2.6524\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8191 - mae: 1.3572 - val_loss: 16.3521 - val_mae: 2.6431\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 7.2469 - mae: 1.8668\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 23ms/step - loss: 592.5955 - mae: 22.4413 - val_loss: 482.3428 - val_mae: 20.0898\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 564.4165 - mae: 21.7821 - val_loss: 453.8108 - val_mae: 19.3155\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 532.8351 - mae: 21.0210 - val_loss: 420.5204 - val_mae: 18.3926\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 493.0821 - mae: 20.0453 - val_loss: 378.8145 - val_mae: 17.1955\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 441.6800 - mae: 18.7866 - val_loss: 328.8082 - val_mae: 15.7318\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 382.0336 - mae: 17.2042 - val_loss: 272.5448 - val_mae: 14.1689\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 312.6937 - mae: 15.2956 - val_loss: 214.0524 - val_mae: 12.4523\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 243.0112 - mae: 13.1232 - val_loss: 157.3399 - val_mae: 10.5550\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 175.5153 - mae: 10.8182 - val_loss: 109.7118 - val_mae: 8.5997\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 119.4992 - mae: 8.6132 - val_loss: 76.6724 - val_mae: 7.0686\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 84.0746 - mae: 7.0098 - val_loss: 57.7855 - val_mae: 6.0211\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7501 - mae: 5.8731 - val_loss: 49.1760 - val_mae: 5.4792\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 52.9852 - mae: 5.2987 - val_loss: 42.7756 - val_mae: 5.1252\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 45.5173 - mae: 4.8720 - val_loss: 37.6919 - val_mae: 4.8408\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39.9052 - mae: 4.5561 - val_loss: 32.4875 - val_mae: 4.4758\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 35.8338 - mae: 4.2894 - val_loss: 28.7407 - val_mae: 4.1857\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32.3952 - mae: 4.0664 - val_loss: 26.3329 - val_mae: 4.0109\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30.2138 - mae: 3.9054 - val_loss: 24.5632 - val_mae: 3.8832\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 28.0733 - mae: 3.7615 - val_loss: 23.2705 - val_mae: 3.7789\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.6433 - mae: 3.6339 - val_loss: 21.9477 - val_mae: 3.6472\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 25.5219 - mae: 3.5302 - val_loss: 20.9425 - val_mae: 3.5567\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 24.3594 - mae: 3.4417 - val_loss: 20.2649 - val_mae: 3.4932\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 23.4608 - mae: 3.3678 - val_loss: 19.8012 - val_mae: 3.4388\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 22.6212 - mae: 3.2922 - val_loss: 19.2263 - val_mae: 3.3686\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.1314 - mae: 3.2607 - val_loss: 19.1754 - val_mae: 3.3730\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 21.2938 - mae: 3.1887 - val_loss: 18.5560 - val_mae: 3.2796\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.6649 - mae: 3.1198 - val_loss: 18.1854 - val_mae: 3.2356\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.1028 - mae: 3.0847 - val_loss: 18.0968 - val_mae: 3.2197\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 19.6730 - mae: 3.0457 - val_loss: 17.7030 - val_mae: 3.1568\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.2281 - mae: 3.0091 - val_loss: 17.5603 - val_mae: 3.1404\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.8444 - mae: 2.9842 - val_loss: 17.5255 - val_mae: 3.1243\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 18.4909 - mae: 2.9488 - val_loss: 17.1663 - val_mae: 3.0698\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.0596 - mae: 2.9181 - val_loss: 17.0705 - val_mae: 3.0569\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.7648 - mae: 2.8882 - val_loss: 16.8717 - val_mae: 3.0130\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.4535 - mae: 2.8592 - val_loss: 16.7233 - val_mae: 3.0048\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.3502 - mae: 2.8746 - val_loss: 17.0394 - val_mae: 3.0435\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.8883 - mae: 2.8433 - val_loss: 16.8229 - val_mae: 3.0147\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.6419 - mae: 2.8182 - val_loss: 16.6149 - val_mae: 3.0117\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.3268 - mae: 2.7893 - val_loss: 16.4914 - val_mae: 2.9635\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.1685 - mae: 2.7685 - val_loss: 16.7325 - val_mae: 2.9663\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.8796 - mae: 2.7548 - val_loss: 16.7516 - val_mae: 2.9749\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.7149 - mae: 2.7485 - val_loss: 16.7899 - val_mae: 2.9823\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.6096 - mae: 2.7497 - val_loss: 16.8217 - val_mae: 2.9985\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.3515 - mae: 2.7185 - val_loss: 16.6757 - val_mae: 2.9847\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.1637 - mae: 2.7050 - val_loss: 16.6467 - val_mae: 2.9800\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.9927 - mae: 2.6889 - val_loss: 16.6155 - val_mae: 2.9805\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.8072 - mae: 2.6757 - val_loss: 16.6047 - val_mae: 2.9707\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6564 - mae: 2.6691 - val_loss: 16.7078 - val_mae: 2.9958\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6031 - mae: 2.6725 - val_loss: 16.6248 - val_mae: 2.9860\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.3999 - mae: 2.6449 - val_loss: 16.4013 - val_mae: 2.9569\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.2810 - mae: 2.6350 - val_loss: 16.4285 - val_mae: 2.9327\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.1395 - mae: 2.6185 - val_loss: 16.4999 - val_mae: 2.9398\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.0653 - mae: 2.6211 - val_loss: 16.7211 - val_mae: 2.9727\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.9668 - mae: 2.6190 - val_loss: 16.7676 - val_mae: 2.9905\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8294 - mae: 2.6097 - val_loss: 16.7797 - val_mae: 2.9759\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7305 - mae: 2.5914 - val_loss: 16.4226 - val_mae: 2.9395\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6843 - mae: 2.5788 - val_loss: 16.4039 - val_mae: 2.9411\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5143 - mae: 2.5703 - val_loss: 16.7640 - val_mae: 2.9849\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4422 - mae: 2.5807 - val_loss: 16.6396 - val_mae: 2.9679\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3377 - mae: 2.5651 - val_loss: 16.6221 - val_mae: 2.9558\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2677 - mae: 2.5544 - val_loss: 16.5303 - val_mae: 2.9457\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2149 - mae: 2.5594 - val_loss: 16.7805 - val_mae: 2.9749\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0993 - mae: 2.5512 - val_loss: 16.2260 - val_mae: 2.9199\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0127 - mae: 2.5240 - val_loss: 16.2352 - val_mae: 2.9251\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9146 - mae: 2.5221 - val_loss: 16.5270 - val_mae: 2.9528\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9313 - mae: 2.5247 - val_loss: 16.4442 - val_mae: 2.9411\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9082 - mae: 2.5346 - val_loss: 17.1085 - val_mae: 3.0213\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7588 - mae: 2.5382 - val_loss: 16.6642 - val_mae: 2.9635\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.6472 - mae: 2.5034 - val_loss: 16.4125 - val_mae: 2.9304\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5862 - mae: 2.4916 - val_loss: 16.3777 - val_mae: 2.9384\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4519 - mae: 2.4798 - val_loss: 16.3524 - val_mae: 2.9283\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3655 - mae: 2.4727 - val_loss: 16.4844 - val_mae: 2.9314\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3501 - mae: 2.4824 - val_loss: 16.7135 - val_mae: 2.9586\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2547 - mae: 2.4765 - val_loss: 16.5114 - val_mae: 2.9479\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.4051 - mae: 2.4708 - val_loss: 15.9931 - val_mae: 2.9205\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1604 - mae: 2.4419 - val_loss: 16.2403 - val_mae: 2.9098\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.1225 - mae: 2.4530 - val_loss: 16.2947 - val_mae: 2.9227\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.0168 - mae: 2.4424 - val_loss: 16.3288 - val_mae: 2.9254\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9320 - mae: 2.4331 - val_loss: 16.1450 - val_mae: 2.9298\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9030 - mae: 2.4235 - val_loss: 16.2689 - val_mae: 2.9268\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.8172 - mae: 2.4114 - val_loss: 16.0604 - val_mae: 2.9148\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.7670 - mae: 2.4084 - val_loss: 16.2274 - val_mae: 2.9164\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6969 - mae: 2.4075 - val_loss: 16.3300 - val_mae: 2.9337\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.6610 - mae: 2.4033 - val_loss: 16.2480 - val_mae: 2.9421\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7055 - mae: 2.4252 - val_loss: 16.6995 - val_mae: 2.9764\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5703 - mae: 2.4102 - val_loss: 16.2954 - val_mae: 2.9274\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4487 - mae: 2.3865 - val_loss: 15.9357 - val_mae: 2.9156\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.5081 - mae: 2.3950 - val_loss: 15.9240 - val_mae: 2.9357\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.4017 - mae: 2.3907 - val_loss: 16.4147 - val_mae: 2.9308\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3557 - mae: 2.3915 - val_loss: 16.2833 - val_mae: 2.9181\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.2073 - mae: 2.3679 - val_loss: 15.8815 - val_mae: 2.9124\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.2173 - mae: 2.3723 - val_loss: 16.1771 - val_mae: 2.9502\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3376 - mae: 2.3623 - val_loss: 15.8731 - val_mae: 2.9160\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1778 - mae: 2.3749 - val_loss: 16.6763 - val_mae: 2.9538\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.0800 - mae: 2.3701 - val_loss: 16.3408 - val_mae: 2.9281\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.9901 - mae: 2.3634 - val_loss: 16.3164 - val_mae: 2.9532\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9883 - mae: 2.3481 - val_loss: 15.6484 - val_mae: 2.8943\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.8769 - mae: 2.3298 - val_loss: 16.0130 - val_mae: 2.9108\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8144 - mae: 2.3279 - val_loss: 15.9764 - val_mae: 2.9206\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.7857 - mae: 2.3276 - val_loss: 15.8840 - val_mae: 2.9003\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.7186 - mae: 2.3204 - val_loss: 15.8595 - val_mae: 2.8969\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6085 - mae: 2.3024 - val_loss: 15.6368 - val_mae: 2.8764\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6044 - mae: 2.3053 - val_loss: 15.7037 - val_mae: 2.8950\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5518 - mae: 2.2951 - val_loss: 15.4564 - val_mae: 2.8689\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5805 - mae: 2.2777 - val_loss: 15.5742 - val_mae: 2.8594\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4877 - mae: 2.2878 - val_loss: 16.1224 - val_mae: 2.9066\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4266 - mae: 2.2872 - val_loss: 15.9477 - val_mae: 2.8852\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3322 - mae: 2.2672 - val_loss: 15.5212 - val_mae: 2.8701\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2815 - mae: 2.2636 - val_loss: 15.6875 - val_mae: 2.8769\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.2331 - mae: 2.2592 - val_loss: 15.5124 - val_mae: 2.8682\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3406 - mae: 2.2696 - val_loss: 16.2083 - val_mae: 2.9174\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1912 - mae: 2.2612 - val_loss: 15.8727 - val_mae: 2.8903\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2980 - mae: 2.2849 - val_loss: 16.3811 - val_mae: 2.9480\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1223 - mae: 2.2720 - val_loss: 15.8128 - val_mae: 2.9064\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0082 - mae: 2.2436 - val_loss: 16.3102 - val_mae: 2.9201\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9172 - mae: 2.2380 - val_loss: 15.9264 - val_mae: 2.8803\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8748 - mae: 2.2243 - val_loss: 15.6732 - val_mae: 2.8716\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7994 - mae: 2.2201 - val_loss: 15.8787 - val_mae: 2.8834\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7610 - mae: 2.2191 - val_loss: 15.8143 - val_mae: 2.8681\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7619 - mae: 2.2191 - val_loss: 15.6995 - val_mae: 2.8793\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6467 - mae: 2.2009 - val_loss: 15.1963 - val_mae: 2.8212\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6740 - mae: 2.1980 - val_loss: 15.2599 - val_mae: 2.8245\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6332 - mae: 2.2016 - val_loss: 15.8115 - val_mae: 2.8921\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6687 - mae: 2.2103 - val_loss: 15.3876 - val_mae: 2.8394\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.4360 - mae: 2.1831 - val_loss: 15.5355 - val_mae: 2.8532\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4331 - mae: 2.1799 - val_loss: 15.3261 - val_mae: 2.8344\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3679 - mae: 2.1738 - val_loss: 15.2943 - val_mae: 2.8389\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.3179 - mae: 2.1701 - val_loss: 15.2670 - val_mae: 2.8376\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3193 - mae: 2.1755 - val_loss: 15.6715 - val_mae: 2.8367\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2552 - mae: 2.1721 - val_loss: 15.5819 - val_mae: 2.8501\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.1919 - mae: 2.1636 - val_loss: 15.0806 - val_mae: 2.8286\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0662 - mae: 2.1424 - val_loss: 15.1108 - val_mae: 2.8136\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0226 - mae: 2.1329 - val_loss: 15.0942 - val_mae: 2.7985\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.0113 - mae: 2.1398 - val_loss: 15.2080 - val_mae: 2.8237\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9068 - mae: 2.1224 - val_loss: 14.8241 - val_mae: 2.7912\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8631 - mae: 2.1106 - val_loss: 14.9584 - val_mae: 2.7855\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8557 - mae: 2.1162 - val_loss: 15.0278 - val_mae: 2.7853\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7722 - mae: 2.1073 - val_loss: 15.0082 - val_mae: 2.8159\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8046 - mae: 2.1171 - val_loss: 14.6061 - val_mae: 2.7657\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7023 - mae: 2.1089 - val_loss: 14.9980 - val_mae: 2.8198\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6072 - mae: 2.1042 - val_loss: 14.9882 - val_mae: 2.7875\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6039 - mae: 2.0836 - val_loss: 14.8501 - val_mae: 2.7804\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5282 - mae: 2.0821 - val_loss: 15.0158 - val_mae: 2.7984\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4523 - mae: 2.0724 - val_loss: 14.8408 - val_mae: 2.7667\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4165 - mae: 2.0624 - val_loss: 14.8306 - val_mae: 2.7699\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3865 - mae: 2.0597 - val_loss: 14.6643 - val_mae: 2.7670\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3897 - mae: 2.0559 - val_loss: 14.9163 - val_mae: 2.7690\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2471 - mae: 2.0375 - val_loss: 14.6812 - val_mae: 2.7615\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3018 - mae: 2.0454 - val_loss: 14.7603 - val_mae: 2.7767\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2867 - mae: 2.0493 - val_loss: 15.1781 - val_mae: 2.7625\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1587 - mae: 2.0278 - val_loss: 14.9028 - val_mae: 2.7711\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1022 - mae: 2.0270 - val_loss: 14.9998 - val_mae: 2.7897\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0877 - mae: 2.0235 - val_loss: 14.5749 - val_mae: 2.7626\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0295 - mae: 2.0062 - val_loss: 14.6236 - val_mae: 2.7360\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0436 - mae: 2.0127 - val_loss: 14.8627 - val_mae: 2.7450\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9711 - mae: 2.0044 - val_loss: 14.7201 - val_mae: 2.7573\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0591 - mae: 2.0000 - val_loss: 14.4747 - val_mae: 2.7299\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8777 - mae: 1.9874 - val_loss: 14.6618 - val_mae: 2.7335\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8556 - mae: 1.9959 - val_loss: 15.1859 - val_mae: 2.7889\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8249 - mae: 2.0043 - val_loss: 14.9071 - val_mae: 2.7618\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8162 - mae: 1.9815 - val_loss: 14.2896 - val_mae: 2.7120\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8206 - mae: 1.9862 - val_loss: 14.7688 - val_mae: 2.7339\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6630 - mae: 1.9676 - val_loss: 14.4753 - val_mae: 2.7276\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6409 - mae: 1.9614 - val_loss: 14.6386 - val_mae: 2.7371\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7647 - mae: 1.9809 - val_loss: 15.6234 - val_mae: 2.8216\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6440 - mae: 1.9749 - val_loss: 14.5419 - val_mae: 2.7245\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6317 - mae: 1.9634 - val_loss: 14.4113 - val_mae: 2.7214\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4436 - mae: 1.9341 - val_loss: 14.9292 - val_mae: 2.7440\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4610 - mae: 1.9528 - val_loss: 14.8664 - val_mae: 2.7339\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4538 - mae: 1.9413 - val_loss: 14.6169 - val_mae: 2.7219\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.4142 - mae: 1.9367 - val_loss: 15.0482 - val_mae: 2.7317\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3228 - mae: 1.9302 - val_loss: 14.8252 - val_mae: 2.7359\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2965 - mae: 1.9327 - val_loss: 14.7446 - val_mae: 2.7369\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2671 - mae: 1.9158 - val_loss: 14.2980 - val_mae: 2.6869\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4920 - mae: 1.9535 - val_loss: 15.1995 - val_mae: 2.7700\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2036 - mae: 1.9297 - val_loss: 14.3470 - val_mae: 2.7061\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1802 - mae: 1.9130 - val_loss: 14.3104 - val_mae: 2.6750\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0847 - mae: 1.8925 - val_loss: 14.2034 - val_mae: 2.6816\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0982 - mae: 1.8961 - val_loss: 14.2325 - val_mae: 2.6746\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0350 - mae: 1.8901 - val_loss: 14.3844 - val_mae: 2.6926\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0332 - mae: 1.8900 - val_loss: 14.4142 - val_mae: 2.6652\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0655 - mae: 1.8855 - val_loss: 14.2543 - val_mae: 2.6863\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9812 - mae: 1.9019 - val_loss: 15.2327 - val_mae: 2.7530\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9795 - mae: 1.8942 - val_loss: 14.3165 - val_mae: 2.6717\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8399 - mae: 1.8681 - val_loss: 14.2228 - val_mae: 2.6524\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9129 - mae: 1.8767 - val_loss: 14.2912 - val_mae: 2.6623\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8324 - mae: 1.8697 - val_loss: 14.0100 - val_mae: 2.6640\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7697 - mae: 1.8575 - val_loss: 14.3289 - val_mae: 2.6513\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7733 - mae: 1.8537 - val_loss: 14.5753 - val_mae: 2.6918\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7254 - mae: 1.8580 - val_loss: 14.4211 - val_mae: 2.6616\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6815 - mae: 1.8447 - val_loss: 14.2223 - val_mae: 2.6677\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6515 - mae: 1.8508 - val_loss: 14.2192 - val_mae: 2.6615\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6667 - mae: 1.8520 - val_loss: 14.1340 - val_mae: 2.6354\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6013 - mae: 1.8373 - val_loss: 14.2067 - val_mae: 2.6634\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5585 - mae: 1.8413 - val_loss: 14.0082 - val_mae: 2.6414\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5728 - mae: 1.8347 - val_loss: 14.2080 - val_mae: 2.6419\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5405 - mae: 1.8206 - val_loss: 14.3012 - val_mae: 2.6465\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4190 - mae: 1.8068 - val_loss: 14.1080 - val_mae: 2.6530\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5295 - mae: 1.8388 - val_loss: 14.3876 - val_mae: 2.6700\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4280 - mae: 1.8192 - val_loss: 13.8553 - val_mae: 2.6189\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3940 - mae: 1.8075 - val_loss: 13.7668 - val_mae: 2.6119\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3433 - mae: 1.8081 - val_loss: 14.2028 - val_mae: 2.6444\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2945 - mae: 1.8049 - val_loss: 14.1691 - val_mae: 2.6460\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2917 - mae: 1.7943 - val_loss: 13.8156 - val_mae: 2.6011\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2729 - mae: 1.7989 - val_loss: 13.9027 - val_mae: 2.6180\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2262 - mae: 1.8033 - val_loss: 14.0472 - val_mae: 2.6404\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1982 - mae: 1.7819 - val_loss: 13.9454 - val_mae: 2.6097\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1582 - mae: 1.7712 - val_loss: 14.1444 - val_mae: 2.6441\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1667 - mae: 1.7932 - val_loss: 13.9987 - val_mae: 2.6208\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1727 - mae: 1.7916 - val_loss: 14.1867 - val_mae: 2.6303\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1664 - mae: 1.7797 - val_loss: 13.9011 - val_mae: 2.5966\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1769 - mae: 1.7950 - val_loss: 13.9186 - val_mae: 2.6347\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0522 - mae: 1.7825 - val_loss: 13.6772 - val_mae: 2.5874\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0712 - mae: 1.7642 - val_loss: 13.7743 - val_mae: 2.6056\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0043 - mae: 1.7525 - val_loss: 13.9319 - val_mae: 2.6004\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9753 - mae: 1.7525 - val_loss: 14.2973 - val_mae: 2.6304\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9516 - mae: 1.7686 - val_loss: 13.8894 - val_mae: 2.6227\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9297 - mae: 1.7616 - val_loss: 13.7769 - val_mae: 2.5877\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9878 - mae: 1.7572 - val_loss: 13.4135 - val_mae: 2.5798\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9241 - mae: 1.7623 - val_loss: 14.0203 - val_mae: 2.6298\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8904 - mae: 1.7312 - val_loss: 13.6723 - val_mae: 2.5861\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8220 - mae: 1.7246 - val_loss: 13.6775 - val_mae: 2.5898\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8345 - mae: 1.7268 - val_loss: 13.4580 - val_mae: 2.5591\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7420 - mae: 1.7178 - val_loss: 13.8187 - val_mae: 2.5851\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8291 - mae: 1.7542 - val_loss: 13.7042 - val_mae: 2.6004\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7091 - mae: 1.7258 - val_loss: 13.7032 - val_mae: 2.5826\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7032 - mae: 1.7188 - val_loss: 13.6417 - val_mae: 2.5729\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6983 - mae: 1.7230 - val_loss: 13.5816 - val_mae: 2.5743\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6764 - mae: 1.7113 - val_loss: 13.9148 - val_mae: 2.5915\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6528 - mae: 1.7166 - val_loss: 13.6390 - val_mae: 2.5775\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5935 - mae: 1.7008 - val_loss: 13.5830 - val_mae: 2.5670\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6085 - mae: 1.7128 - val_loss: 13.4554 - val_mae: 2.5670\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8027 - mae: 1.7627 - val_loss: 14.3321 - val_mae: 2.6412\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6232 - mae: 1.7433 - val_loss: 13.2583 - val_mae: 2.5698\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5620 - mae: 1.6964 - val_loss: 13.7490 - val_mae: 2.5644\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5344 - mae: 1.7008 - val_loss: 13.8150 - val_mae: 2.5913\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5130 - mae: 1.7049 - val_loss: 14.0045 - val_mae: 2.6037\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5625 - mae: 1.6970 - val_loss: 13.3040 - val_mae: 2.5586\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3841 - mae: 1.7035 - val_loss: 14.5213 - val_mae: 2.6487\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.5419 - mae: 1.7260 - val_loss: 14.0613 - val_mae: 2.6254\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4988 - mae: 1.7121 - val_loss: 13.3962 - val_mae: 2.5615\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3829 - mae: 1.6894 - val_loss: 13.6466 - val_mae: 2.5773\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3686 - mae: 1.6891 - val_loss: 13.8791 - val_mae: 2.5876\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2481 - mae: 1.6814 - val_loss: 13.2371 - val_mae: 2.5587\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3202 - mae: 1.6823 - val_loss: 13.3571 - val_mae: 2.5514\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2779 - mae: 1.6732 - val_loss: 13.5429 - val_mae: 2.5602\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2398 - mae: 1.6587 - val_loss: 13.5927 - val_mae: 2.5588\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2948 - mae: 1.6811 - val_loss: 13.4997 - val_mae: 2.5588\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2612 - mae: 1.6586 - val_loss: 13.3240 - val_mae: 2.5297\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2626 - mae: 1.6810 - val_loss: 13.5740 - val_mae: 2.5702\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2809 - mae: 1.6598 - val_loss: 13.2741 - val_mae: 2.5293\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1207 - mae: 1.6419 - val_loss: 13.7881 - val_mae: 2.5862\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2091 - mae: 1.6796 - val_loss: 13.9119 - val_mae: 2.5993\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2024 - mae: 1.6616 - val_loss: 13.2899 - val_mae: 2.5285\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1331 - mae: 1.6668 - val_loss: 13.4352 - val_mae: 2.5547\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0860 - mae: 1.6496 - val_loss: 13.5780 - val_mae: 2.5565\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0777 - mae: 1.6490 - val_loss: 13.4061 - val_mae: 2.5397\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0408 - mae: 1.6498 - val_loss: 13.4383 - val_mae: 2.5427\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0198 - mae: 1.6368 - val_loss: 13.4506 - val_mae: 2.5271\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0430 - mae: 1.6389 - val_loss: 13.3834 - val_mae: 2.5347\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0482 - mae: 1.6437 - val_loss: 13.7068 - val_mae: 2.5635\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9916 - mae: 1.6337 - val_loss: 13.1941 - val_mae: 2.5112\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9590 - mae: 1.6199 - val_loss: 13.5149 - val_mae: 2.5412\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9368 - mae: 1.6296 - val_loss: 13.2565 - val_mae: 2.5275\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8809 - mae: 1.6120 - val_loss: 13.4594 - val_mae: 2.5326\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8748 - mae: 1.6176 - val_loss: 13.5217 - val_mae: 2.5462\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9232 - mae: 1.6341 - val_loss: 13.2264 - val_mae: 2.5274\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9741 - mae: 1.6403 - val_loss: 13.5265 - val_mae: 2.5472\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9550 - mae: 1.6483 - val_loss: 13.0309 - val_mae: 2.5208\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.8175 - mae: 1.5966 - val_loss: 13.3183 - val_mae: 2.5086\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8790 - mae: 1.6162 - val_loss: 13.4291 - val_mae: 2.5375\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.8779 - mae: 1.6255 - val_loss: 13.7812 - val_mae: 2.5564\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7269 - mae: 1.5870 - val_loss: 13.0500 - val_mae: 2.5199\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8071 - mae: 1.6078 - val_loss: 13.3904 - val_mae: 2.5209\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8588 - mae: 1.6284 - val_loss: 13.8519 - val_mae: 2.5612\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7487 - mae: 1.6158 - val_loss: 13.1909 - val_mae: 2.5290\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7236 - mae: 1.5956 - val_loss: 13.1964 - val_mae: 2.5008\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6670 - mae: 1.5858 - val_loss: 13.6963 - val_mae: 2.5534\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7012 - mae: 1.5899 - val_loss: 13.2642 - val_mae: 2.5224\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6766 - mae: 1.5857 - val_loss: 13.4133 - val_mae: 2.5330\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7676 - mae: 1.6131 - val_loss: 13.3064 - val_mae: 2.5193\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6595 - mae: 1.6077 - val_loss: 13.2810 - val_mae: 2.5345\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6316 - mae: 1.5838 - val_loss: 13.4624 - val_mae: 2.5203\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6135 - mae: 1.5772 - val_loss: 13.2660 - val_mae: 2.5168\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5647 - mae: 1.5788 - val_loss: 13.3065 - val_mae: 2.5205\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5743 - mae: 1.5787 - val_loss: 13.5034 - val_mae: 2.5288\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5329 - mae: 1.5794 - val_loss: 13.4627 - val_mae: 2.5309\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4991 - mae: 1.5623 - val_loss: 13.0110 - val_mae: 2.4998\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5174 - mae: 1.5607 - val_loss: 13.3497 - val_mae: 2.5209\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4982 - mae: 1.5548 - val_loss: 13.5986 - val_mae: 2.5260\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4749 - mae: 1.5502 - val_loss: 13.2466 - val_mae: 2.5243\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5241 - mae: 1.5765 - val_loss: 13.8807 - val_mae: 2.5625\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4707 - mae: 1.5601 - val_loss: 13.5205 - val_mae: 2.5206\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4079 - mae: 1.5533 - val_loss: 13.4306 - val_mae: 2.5190\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4002 - mae: 1.5474 - val_loss: 13.5199 - val_mae: 2.5271\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4643 - mae: 1.5421 - val_loss: 13.2647 - val_mae: 2.5098\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4474 - mae: 1.5600 - val_loss: 13.5119 - val_mae: 2.5316\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4618 - mae: 1.5620 - val_loss: 13.6612 - val_mae: 2.5256\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3660 - mae: 1.5438 - val_loss: 13.4842 - val_mae: 2.5562\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3932 - mae: 1.5589 - val_loss: 13.4587 - val_mae: 2.5170\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 10.2898 - mae: 2.2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-폴드 교차 검증으로 k=3으로 설정하여 진행했다. 이는 반복마다 전체 데이터를 3등분하여 두 개는 학습 데이터셋, 나머지 한 개는 검증 데이터셋으로 활용하겠다는 것을 의미한다. 또한, 모델을 반환하는 get_model() 함수를 정의하여 총 세 개의 개별적 모델을 사용하도록 했다."
      ],
      "metadata": {
        "id": "xziQq6mYxb-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-폴드 결과 확인\n",
        "print(mae_list)\n",
        "print(np.mean(mae_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8n3im-wxtrJ",
        "outputId": "9c2202bc-2101-47d7-fb75-654e4a34b172"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.1574857234954834, 1.8667776584625244, 2.202263355255127]\n",
            "2.0755089124043784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차 검증을 사용하지 않은 이전 모델보다 향상된 결과를 얻었다. (2.0978 -> 2.0755)\n",
        "\n",
        "하지만 세 개의 모델이 전부 좋은 성능을 보이진 않는다. 이러한 차이가 존재하는 이유는 전체 데이터셋은 같지만 각 폴드에서 학습 및 검증에 사용한 데이터가 다르기 때문이다. 두 번째 모델은 상대적으로 테스트 데이터와 비슷한 데이터를 학습한 경우라고 해석할 수도 있다. 이런 문제 때문에 최종적으로는 세 개 모델의 결괏값을 평균내어 사용한다. 따라서 위의 교차 검증을 활용한 방법의 최종 성능은 2.075이 된다.\n",
        "\n",
        "교차 검증은 모델의 성능을 향상시킬 수 있는 좋은 방법이다. 하지만 이보다 중요한 것은 데이터의 특성을 잘 파악하는 것임을 명심해야 한다."
      ],
      "metadata": {
        "id": "C2Pn7p0gx0i2"
      }
    }
  ]
}